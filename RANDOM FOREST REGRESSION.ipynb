{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T05:01:02.374586Z",
     "start_time": "2018-02-16T05:00:35.167811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "displaying the exoplanet train set (10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>211.10</td>\n",
       "      <td>163.57</td>\n",
       "      <td>179.16</td>\n",
       "      <td>187.82</td>\n",
       "      <td>188.46</td>\n",
       "      <td>168.13</td>\n",
       "      <td>203.46</td>\n",
       "      <td>178.65</td>\n",
       "      <td>166.49</td>\n",
       "      <td>...</td>\n",
       "      <td>-98.45</td>\n",
       "      <td>30.34</td>\n",
       "      <td>30.34</td>\n",
       "      <td>29.62</td>\n",
       "      <td>28.80</td>\n",
       "      <td>19.27</td>\n",
       "      <td>-43.90</td>\n",
       "      <td>-41.63</td>\n",
       "      <td>-52.90</td>\n",
       "      <td>-16.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>9.34</td>\n",
       "      <td>49.96</td>\n",
       "      <td>33.30</td>\n",
       "      <td>9.63</td>\n",
       "      <td>37.64</td>\n",
       "      <td>20.85</td>\n",
       "      <td>4.54</td>\n",
       "      <td>22.42</td>\n",
       "      <td>10.11</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.56</td>\n",
       "      <td>9.93</td>\n",
       "      <td>9.93</td>\n",
       "      <td>23.50</td>\n",
       "      <td>5.28</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>10.90</td>\n",
       "      <td>-11.77</td>\n",
       "      <td>-9.25</td>\n",
       "      <td>-36.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>238.77</td>\n",
       "      <td>262.16</td>\n",
       "      <td>277.80</td>\n",
       "      <td>190.16</td>\n",
       "      <td>180.98</td>\n",
       "      <td>123.27</td>\n",
       "      <td>103.95</td>\n",
       "      <td>50.70</td>\n",
       "      <td>59.91</td>\n",
       "      <td>...</td>\n",
       "      <td>-72.48</td>\n",
       "      <td>31.77</td>\n",
       "      <td>31.77</td>\n",
       "      <td>53.48</td>\n",
       "      <td>27.88</td>\n",
       "      <td>95.30</td>\n",
       "      <td>48.86</td>\n",
       "      <td>-10.62</td>\n",
       "      <td>-112.02</td>\n",
       "      <td>-229.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>-103.54</td>\n",
       "      <td>-118.97</td>\n",
       "      <td>-108.93</td>\n",
       "      <td>-72.25</td>\n",
       "      <td>-61.46</td>\n",
       "      <td>-50.16</td>\n",
       "      <td>-20.61</td>\n",
       "      <td>-12.44</td>\n",
       "      <td>1.48</td>\n",
       "      <td>...</td>\n",
       "      <td>43.92</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>-7.45</td>\n",
       "      <td>-18.82</td>\n",
       "      <td>4.53</td>\n",
       "      <td>21.95</td>\n",
       "      <td>26.94</td>\n",
       "      <td>34.08</td>\n",
       "      <td>44.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>-265.91</td>\n",
       "      <td>-318.59</td>\n",
       "      <td>-335.66</td>\n",
       "      <td>-450.47</td>\n",
       "      <td>-453.09</td>\n",
       "      <td>-561.47</td>\n",
       "      <td>-606.03</td>\n",
       "      <td>-712.72</td>\n",
       "      <td>-685.97</td>\n",
       "      <td>...</td>\n",
       "      <td>3671.03</td>\n",
       "      <td>2249.28</td>\n",
       "      <td>2249.28</td>\n",
       "      <td>2437.78</td>\n",
       "      <td>2584.22</td>\n",
       "      <td>3162.53</td>\n",
       "      <td>3398.28</td>\n",
       "      <td>3648.34</td>\n",
       "      <td>3671.97</td>\n",
       "      <td>3781.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7  \\\n",
       "0      2    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n",
       "1      2   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
       "2      2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
       "3      2   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
       "4      2 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
       "5      2   211.10   163.57   179.16   187.82   188.46   168.13  203.46   \n",
       "6      2     9.34    49.96    33.30     9.63    37.64    20.85    4.54   \n",
       "7      2   238.77   262.16   277.80   190.16   180.98   123.27  103.95   \n",
       "8      2  -103.54  -118.97  -108.93   -72.25   -61.46   -50.16  -20.61   \n",
       "9      2  -265.91  -318.59  -335.66  -450.47  -453.09  -561.47 -606.03   \n",
       "\n",
       "    FLUX.8  FLUX.9    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0   -96.27  -79.89    ...         -78.07    -102.15    -102.15      25.13   \n",
       "1   -85.33  -83.97    ...          -3.28     -32.21     -32.21     -24.89   \n",
       "2   486.39  436.56    ...         -71.69      13.31      13.31     -29.89   \n",
       "3   311.31  312.42    ...           5.71      -3.73      -3.73      30.05   \n",
       "4 -1022.71 -989.57    ...        -594.37    -401.66    -401.66    -357.24   \n",
       "5   178.65  166.49    ...         -98.45      30.34      30.34      29.62   \n",
       "6    22.42   10.11    ...         -58.56       9.93       9.93      23.50   \n",
       "7    50.70   59.91    ...         -72.48      31.77      31.77      53.48   \n",
       "8   -12.44    1.48    ...          43.92       7.24       7.24      -7.45   \n",
       "9  -712.72 -685.97    ...        3671.03    2249.28    2249.28    2437.78   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "5      28.80      19.27     -43.90     -41.63     -52.90     -16.16  \n",
       "6       5.28      -0.44      10.90     -11.77      -9.25     -36.69  \n",
       "7      27.88      95.30      48.86     -10.62    -112.02    -229.92  \n",
       "8     -18.82       4.53      21.95      26.94      34.08      44.65  \n",
       "9    2584.22    3162.53    3398.28    3648.34    3671.97    3781.91  \n",
       "\n",
       "[10 rows x 3198 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "displaying the exoplanet test set (10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>119.88</td>\n",
       "      <td>100.21</td>\n",
       "      <td>86.46</td>\n",
       "      <td>48.68</td>\n",
       "      <td>46.12</td>\n",
       "      <td>39.39</td>\n",
       "      <td>18.57</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.63</td>\n",
       "      <td>...</td>\n",
       "      <td>14.52</td>\n",
       "      <td>19.29</td>\n",
       "      <td>14.44</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>13.33</td>\n",
       "      <td>45.50</td>\n",
       "      <td>31.93</td>\n",
       "      <td>35.78</td>\n",
       "      <td>269.43</td>\n",
       "      <td>57.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5736.59</td>\n",
       "      <td>5699.98</td>\n",
       "      <td>5717.16</td>\n",
       "      <td>5692.73</td>\n",
       "      <td>5663.83</td>\n",
       "      <td>5631.16</td>\n",
       "      <td>5626.39</td>\n",
       "      <td>5569.47</td>\n",
       "      <td>5550.44</td>\n",
       "      <td>...</td>\n",
       "      <td>-581.91</td>\n",
       "      <td>-984.09</td>\n",
       "      <td>-1230.89</td>\n",
       "      <td>-1600.45</td>\n",
       "      <td>-1824.53</td>\n",
       "      <td>-2061.17</td>\n",
       "      <td>-2265.98</td>\n",
       "      <td>-2366.19</td>\n",
       "      <td>-2294.86</td>\n",
       "      <td>-2034.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>844.48</td>\n",
       "      <td>817.49</td>\n",
       "      <td>770.07</td>\n",
       "      <td>675.01</td>\n",
       "      <td>605.52</td>\n",
       "      <td>499.45</td>\n",
       "      <td>440.77</td>\n",
       "      <td>362.95</td>\n",
       "      <td>207.27</td>\n",
       "      <td>...</td>\n",
       "      <td>17.82</td>\n",
       "      <td>-51.66</td>\n",
       "      <td>-48.29</td>\n",
       "      <td>-59.99</td>\n",
       "      <td>-82.10</td>\n",
       "      <td>-174.54</td>\n",
       "      <td>-95.23</td>\n",
       "      <td>-162.68</td>\n",
       "      <td>-36.79</td>\n",
       "      <td>30.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-826.00</td>\n",
       "      <td>-827.31</td>\n",
       "      <td>-846.12</td>\n",
       "      <td>-836.03</td>\n",
       "      <td>-745.50</td>\n",
       "      <td>-784.69</td>\n",
       "      <td>-791.22</td>\n",
       "      <td>-746.50</td>\n",
       "      <td>-709.53</td>\n",
       "      <td>...</td>\n",
       "      <td>122.34</td>\n",
       "      <td>93.03</td>\n",
       "      <td>93.03</td>\n",
       "      <td>68.81</td>\n",
       "      <td>9.81</td>\n",
       "      <td>20.75</td>\n",
       "      <td>20.25</td>\n",
       "      <td>-120.81</td>\n",
       "      <td>-257.56</td>\n",
       "      <td>-215.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-39.57</td>\n",
       "      <td>-15.88</td>\n",
       "      <td>-9.16</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-16.13</td>\n",
       "      <td>-24.05</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-45.20</td>\n",
       "      <td>-5.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.87</td>\n",
       "      <td>-61.85</td>\n",
       "      <td>-27.15</td>\n",
       "      <td>-21.18</td>\n",
       "      <td>-33.76</td>\n",
       "      <td>-85.34</td>\n",
       "      <td>-81.46</td>\n",
       "      <td>-61.98</td>\n",
       "      <td>-69.34</td>\n",
       "      <td>-17.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>14.28</td>\n",
       "      <td>10.63</td>\n",
       "      <td>14.56</td>\n",
       "      <td>12.42</td>\n",
       "      <td>12.07</td>\n",
       "      <td>12.92</td>\n",
       "      <td>12.27</td>\n",
       "      <td>3.19</td>\n",
       "      <td>8.47</td>\n",
       "      <td>...</td>\n",
       "      <td>3.86</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>-3.56</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>-7.18</td>\n",
       "      <td>-4.78</td>\n",
       "      <td>-4.34</td>\n",
       "      <td>7.67</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-7.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>-150.48</td>\n",
       "      <td>-141.72</td>\n",
       "      <td>-157.60</td>\n",
       "      <td>-184.60</td>\n",
       "      <td>-164.89</td>\n",
       "      <td>-173.87</td>\n",
       "      <td>-162.91</td>\n",
       "      <td>-167.04</td>\n",
       "      <td>-172.76</td>\n",
       "      <td>...</td>\n",
       "      <td>7.15</td>\n",
       "      <td>5.16</td>\n",
       "      <td>-9.08</td>\n",
       "      <td>-39.11</td>\n",
       "      <td>-32.31</td>\n",
       "      <td>-8.40</td>\n",
       "      <td>-16.80</td>\n",
       "      <td>-8.03</td>\n",
       "      <td>-12.73</td>\n",
       "      <td>-11.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>-10.06</td>\n",
       "      <td>-12.78</td>\n",
       "      <td>-13.16</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>-18.91</td>\n",
       "      <td>-20.33</td>\n",
       "      <td>-22.85</td>\n",
       "      <td>-19.17</td>\n",
       "      <td>-17.97</td>\n",
       "      <td>...</td>\n",
       "      <td>21.49</td>\n",
       "      <td>30.63</td>\n",
       "      <td>24.19</td>\n",
       "      <td>33.00</td>\n",
       "      <td>35.70</td>\n",
       "      <td>35.89</td>\n",
       "      <td>-33.44</td>\n",
       "      <td>-30.83</td>\n",
       "      <td>-33.00</td>\n",
       "      <td>-20.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>454.66</td>\n",
       "      <td>440.60</td>\n",
       "      <td>382.29</td>\n",
       "      <td>361.63</td>\n",
       "      <td>298.63</td>\n",
       "      <td>253.29</td>\n",
       "      <td>155.86</td>\n",
       "      <td>110.38</td>\n",
       "      <td>31.71</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.78</td>\n",
       "      <td>-61.64</td>\n",
       "      <td>-120.32</td>\n",
       "      <td>-65.39</td>\n",
       "      <td>-126.75</td>\n",
       "      <td>-78.18</td>\n",
       "      <td>-184.39</td>\n",
       "      <td>-142.31</td>\n",
       "      <td>-113.12</td>\n",
       "      <td>-111.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>187.40</td>\n",
       "      <td>209.60</td>\n",
       "      <td>199.91</td>\n",
       "      <td>179.62</td>\n",
       "      <td>171.21</td>\n",
       "      <td>161.84</td>\n",
       "      <td>163.02</td>\n",
       "      <td>171.61</td>\n",
       "      <td>113.53</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.75</td>\n",
       "      <td>-35.72</td>\n",
       "      <td>-21.93</td>\n",
       "      <td>-16.47</td>\n",
       "      <td>-21.84</td>\n",
       "      <td>-26.64</td>\n",
       "      <td>-13.90</td>\n",
       "      <td>17.03</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6   FLUX.7  \\\n",
       "0      2   119.88   100.21    86.46    48.68    46.12    39.39    18.57   \n",
       "1      2  5736.59  5699.98  5717.16  5692.73  5663.83  5631.16  5626.39   \n",
       "2      2   844.48   817.49   770.07   675.01   605.52   499.45   440.77   \n",
       "3      2  -826.00  -827.31  -846.12  -836.03  -745.50  -784.69  -791.22   \n",
       "4      2   -39.57   -15.88    -9.16    -6.37   -16.13   -24.05    -0.90   \n",
       "5      1    14.28    10.63    14.56    12.42    12.07    12.92    12.27   \n",
       "6      1  -150.48  -141.72  -157.60  -184.60  -164.89  -173.87  -162.91   \n",
       "7      1   -10.06   -12.78   -13.16    -9.81   -18.91   -20.33   -22.85   \n",
       "8      1   454.66   440.60   382.29   361.63   298.63   253.29   155.86   \n",
       "9      1   187.40   209.60   199.91   179.62   171.21   161.84   163.02   \n",
       "\n",
       "    FLUX.8   FLUX.9    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0     6.98     6.63    ...          14.52      19.29      14.44      -1.62   \n",
       "1  5569.47  5550.44    ...        -581.91    -984.09   -1230.89   -1600.45   \n",
       "2   362.95   207.27    ...          17.82     -51.66     -48.29     -59.99   \n",
       "3  -746.50  -709.53    ...         122.34      93.03      93.03      68.81   \n",
       "4   -45.20    -5.04    ...         -37.87     -61.85     -27.15     -21.18   \n",
       "5     3.19     8.47    ...           3.86      -4.06      -3.56      -1.13   \n",
       "6  -167.04  -172.76    ...           7.15       5.16      -9.08     -39.11   \n",
       "7   -19.17   -17.97    ...          21.49      30.63      24.19      33.00   \n",
       "8   110.38    31.71    ...         -56.78     -61.64    -120.32     -65.39   \n",
       "9   171.61   113.53    ...         -23.75     -35.72     -21.93     -16.47   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      13.33      45.50      31.93      35.78     269.43      57.72  \n",
       "1   -1824.53   -2061.17   -2265.98   -2366.19   -2294.86   -2034.72  \n",
       "2     -82.10    -174.54     -95.23    -162.68     -36.79      30.63  \n",
       "3       9.81      20.75      20.25    -120.81    -257.56    -215.41  \n",
       "4     -33.76     -85.34     -81.46     -61.98     -69.34     -17.84  \n",
       "5      -7.18      -4.78      -4.34       7.67      -0.33      -7.53  \n",
       "6     -32.31      -8.40     -16.80      -8.03     -12.73     -11.41  \n",
       "7      35.70      35.89     -33.44     -30.83     -33.00     -20.15  \n",
       "8    -126.75     -78.18    -184.39    -142.31    -113.12    -111.78  \n",
       "9     -21.84     -26.64     -13.90      17.03       4.36       2.91  \n",
       "\n",
       "[10 rows x 3198 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print('displaying the exoplanet train set (10)')\n",
    "exo_train = pd.read_csv('exoTrain.csv')\n",
    "display(exo_train[:10])\n",
    "print('displaying the exoplanet test set (10)')\n",
    "exo_test = pd.read_csv('exoTest.csv')\n",
    "display(exo_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T05:04:16.113137Z",
     "start_time": "2018-02-16T05:04:16.097111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXOPLANET TRAIN dataset has 5087 data points with 3198 variables each.\n",
      "EXOPLANET TEST dataset has 570 data points with 3198 variables each.\n"
     ]
    }
   ],
   "source": [
    "print (\"EXOPLANET TRAIN dataset has {} data points with {} variables each.\".format(*exo_train.shape))\n",
    "\n",
    "# print (\"ATLAS TRAIN dataset has {} data points with {} variables each.\".format(train_data))\n",
    "print (\"EXOPLANET TEST dataset has {} data points with {} variables each.\".format(*exo_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T05:04:17.270952Z",
     "start_time": "2018-02-16T05:04:17.235226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING ACCURACY PERFOMANCE METRIC\n",
      "CREATED PERFOMANCE METRIC\n"
     ]
    }
   ],
   "source": [
    "print('CREATING ACCURACY PERFOMANCE METRIC')\n",
    "def R2_performance_metric(y_true, y_predict):\n",
    "    from sklearn.metrics import accuracy_score,roc_curve, roc_auc_score,r2_score\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    score = r2_score(y_true, y_predict)\n",
    "\n",
    "    # Return the score\n",
    "    return score\n",
    "print('CREATED PERFOMANCE METRIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T05:07:16.492768Z",
     "start_time": "2018-02-16T05:07:16.360801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting the RandomForestClassifier to a DECISIONTREETREGRESSOR \n",
      " \n",
      " \n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor,RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "# print('fitting the data to an ADABOOSTREGRESSOR \\n , params:= \\n n_estimators:[200,150,100,50,25,20,10,5], \\n learning_rate:[.7,.6,.5,.4,.25,.1], \\n LOSS: linear, square,exponential')\n",
    "print('fitting the RandomForestClassifier to a DECISIONTREETREGRESSOR \\n \\n \\n  ')\n",
    "def fit_model(x, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    cv_sets = ShuffleSplit(x.shape[0], n_iter = 15, test_size = 0.30, random_state =None)\n",
    "    \n",
    "    # TODO: Create a decision tree regressor object\n",
    "    regressor = RandomForestRegressor(DecisionTreeRegressor(criterion='friedman_mse',max_depth=300,max_leaf_nodes=150,\n",
    "                                                              min_samples_leaf=12, min_samples_split=9))\n",
    "\n",
    "    # TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "    params = {'n_estimators':[200,150,100,50,5],\n",
    "          'verbose':[True],\n",
    "          'criterion':['mse','mae'],\n",
    "            'n_jobs':[-1],\n",
    "              'oob_score':[True],\n",
    "              'max_depth':[2500,40,30,20,10,5],\n",
    "              'max_features':['auto'],\n",
    "              'bootstrap':[True],\n",
    "              \n",
    "             }\n",
    "\n",
    "    # TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(R2_performance_metric)\n",
    "\n",
    "    # TODO: Create the grid search object\n",
    "    grid = GridSearchCV(regressor, params, scoring = scoring_fnc, cv = cv_sets)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(x, y)\n",
    "\n",
    "    # Return the optimal model after fitting the data\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T05:07:19.113036Z",
     "start_time": "2018-02-16T05:07:18.544421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LABEL\n",
      "713       1\n",
      "1140      1\n",
      "3189      1\n",
      "4076      1\n",
      "2924      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# ex_test = pd.read_csv('exoTest.csv')\n",
    "# ex_train = pd.read_csv('exoTrain.csv')\n",
    "label = exo_train[['LABEL']]\n",
    "new_label = exo_train.drop(['LABEL'], axis = 1)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test  = train_test_split(new_label,\n",
    "                                                 label,\n",
    "                                                 test_size=.3)\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T05:07:22.253077Z",
     "start_time": "2018-02-16T05:07:22.208759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6   FLUX.7   FLUX.8  \\\n",
      "713   9502.50  9482.31  9500.06  9474.12  9497.38  9482.19  9397.31  9364.50   \n",
      "1140   -30.89   -23.12   -16.66    -9.28   -17.44    12.77    10.66    19.53   \n",
      "3189    18.78     7.80    14.06     8.77     7.90    10.15     8.14     7.41   \n",
      "4076    20.27    18.10    17.20    13.70    14.81    14.26    12.82    12.07   \n",
      "2924   -71.25   -68.20   -60.13   -73.82   -88.70   -94.08   -85.46   -70.41   \n",
      "\n",
      "       FLUX.9  FLUX.10    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
      "713   9273.19  9211.69    ...       -4236.94   -4302.50   -4341.62   -4240.44   \n",
      "1140    12.22    10.07    ...         -25.67     -27.10     -15.95     -27.53   \n",
      "3189     5.33     7.64    ...           2.77       7.81       3.03      16.59   \n",
      "4076     9.32    13.06    ...          10.25       6.26       7.90      12.87   \n",
      "2924   -81.11   -71.28    ...          30.74       1.94     -14.19     -37.14   \n",
      "\n",
      "      FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
      "713    -4288.94   -4116.81   -4850.38   -5060.62   -5154.69   -5240.50  \n",
      "1140     -15.60     -27.77      19.59      22.87       0.37      -6.29  \n",
      "3189       7.46       8.92       3.67      11.01       0.90      -0.79  \n",
      "4076       8.17      11.59      -4.29      -6.68      -3.44      -4.50  \n",
      "2924     -40.02     -42.90     -39.90     -24.69     -37.60     -26.18  \n",
      "\n",
      "[5 rows x 3197 columns]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T05:07:24.240626Z",
     "start_time": "2018-02-16T05:07:24.214701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LABEL\n",
      "3811      1\n",
      "371       1\n",
      "3694      1\n",
      "3537      1\n",
      "679       1\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T05:07:26.192159Z",
     "start_time": "2018-02-16T05:07:26.129761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      FLUX.1  FLUX.2  FLUX.3  FLUX.4  FLUX.5  FLUX.6  FLUX.7  FLUX.8  FLUX.9  \\\n",
      "3811    3.81    2.20    1.31    4.56    1.29    0.97    0.24    2.87   -0.69   \n",
      "371  -619.00 -718.87 -553.18 -436.43 -364.68 -441.81 -267.93 -154.56  -88.06   \n",
      "3694   42.25   77.45   27.09   35.42   20.81   66.30   13.56   68.95   42.03   \n",
      "3537  -65.86  -48.61  -68.63  -40.91  -15.11  -28.70   29.71   38.04   43.37   \n",
      "679   -25.71  -43.37  -77.77  -35.61  -18.48  -48.97    0.00   40.67   31.39   \n",
      "\n",
      "      FLUX.10    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
      "3811    -0.56    ...           2.65       3.36       5.04       6.80   \n",
      "371    -74.81    ...         286.32     322.32     266.57     446.13   \n",
      "3694    41.94    ...         -82.13     -72.20     -26.72     -17.58   \n",
      "3537    47.30    ...          48.24      22.29      38.78      -1.21   \n",
      "679     20.45    ...         -25.85     -38.32     -62.89     -76.93   \n",
      "\n",
      "      FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
      "3811       7.95       8.53      -4.36      -3.20      -6.63      -1.84  \n",
      "371      332.32     335.88     277.63     548.19     561.26     472.07  \n",
      "3694     -39.42     -31.67      -3.77      21.34      -8.84     -72.16  \n",
      "3537     -26.31     -49.02      14.05     -21.77     -42.21     -30.86  \n",
      "679      -78.61     -87.18       2.05       6.93     -33.56     -17.36  \n",
      "\n",
      "[5 rows x 3197 columns]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T09:49:09.439598Z",
     "start_time": "2018-02-16T05:07:28.032965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COFFE BREAK \n",
      " FITTING THE GRID TO THE PARAMETERS.. \n",
      " NAPS ARE NICE TOO ^__^\n",
      "eta 1 hour 15 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.6min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  3.8min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.8min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.0min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   50.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  3.9min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   59.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.7min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.0min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  3.4min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.7min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   50.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.6min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  6.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   53.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   56.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  3.9min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   54.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  4.8min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   53.4s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.4min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   51.9s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.8min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   54.9s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   55.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   57.0s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.4min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.6min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   57.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   54.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   53.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   50.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   59.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.6min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   46.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   49.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   58.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   55.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   59.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   56.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   43.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   55.3s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   58.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   57.8s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.6s finished\n",
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.9s finished\n",
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    8.9s finished\n",
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.5s finished\n",
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    8.7s finished\n",
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.6s finished\n",
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   11.1s finished\n",
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.3s finished\n",
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.8s finished\n",
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.6s finished\n",
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.4s finished\n",
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.2s finished\n",
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    8.1s finished\n",
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.4s finished\n",
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.6s finished\n",
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py:724: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "[Parallel(n_jobs=4)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  3.8min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   59.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.5min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.9min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.5min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   57.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.6min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   56.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  5.0min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  5.0min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  5.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.7min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  5.1min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  5.3min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  5.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.5min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.0min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.6min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.6min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.4min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.4min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.6min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.8min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-35da8a4f9d2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdaBoostRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'eta 1 hour 15 minutes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'BEEP!! BEEP!!! BEEEEEPPP!!!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-0fa8b0575bee>\u001b[0m in \u001b[0;36mfit_model\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# Fit the grid search object to the data to compute the optimal model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# Return the optimal model after fitting the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m         \"\"\"\n\u001b[1;32m--> 838\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 574\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m                 for train, test in cv)\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[0;32m   1673\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1675\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1677\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('COFFE BREAK \\n FITTING THE GRID TO THE PARAMETERS.. \\n NAPS ARE NICE TOO ^__^')\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "print('eta 1 hour 15 minutes')\n",
    "reg = fit_model(x_train, y_train.values.ravel())\n",
    "print('BEEP!! BEEP!!! BEEEEEPPP!!!')\n",
    "\n",
    "print('eta 1 hour 15 minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA, PCA\n",
    "print('transforming the ADABOOSTREGRESSOR DATA')\n",
    "ADB_REG= AdaBoostRegressor((reg), n_estimators = 150, learning_rate = .4)\n",
    "ADB_REG.fit(x_train,y_train)\n",
    "\n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ADB_REG)\n",
    "display(ADB_REG.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ADB_REG.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(reg.decision_path(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ADB_REG.decision_function(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RANDOM INDEPENDENT/PRINCIPAL COMPONENT ANALYSIS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICA1_REG = FastICA(n_components= 2, algorithm='deflation', whiten=True, fun='logcosh', fun_args= {'alpha' :1.7}, max_iter=500, tol=0.0025, random_state=111111)\n",
    "\n",
    "PCA_REG = PCA(n_components=2,whiten=True,tol=.0025,random_state=111111, svd_solver ='arpack')\n",
    "print('ICA CLF')\n",
    "# ICA.fit(x_train) #y ignored\n",
    "print(ICA1_REG)\n",
    "\n",
    "print('PCA CLF')\n",
    "print(PCA_REG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('transforming the Ica data')\n",
    "ICA_REG_T = ICA1_REG.fit_transform(x_train)\n",
    "print('transforming the Pca data')\n",
    "PCA_REG_T = PCA_REG.fit_transform(x_train)\n",
    "\n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ADB_REG.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ADB_REG.score(x_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
