{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Random Forest is a bagging algorithm rather than a boosting algorithm. They are two opposite way to achieve a low error.\n",
    "We know that error can be composited from bias and variance. A too complex model has low bias but large variance, while a too simple model has low variance but large bias, both leading a high error but two different reasons. As a result, two different ways to solve the problem come into people's mind (maybe Breiman and others), variance reduction for a complex model, or bias reduction for a simple model, which refers to random forest and boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is an extension of bagging. The procedure is as follows, you take a bootstrap sample of your data and then use this to grow a classification or regression tree (CART). This is done a predefined number of times and the prediction is then the aggregation of the individual trees predictions, it could be a majority vote (for classification) or an average (for regression). This approach is called bagging (Breiman 1994). Furthermore the candidate variable for each split of each tree is taken from a random sample of all the available independent variables. This introduces even more variability and makes the trees more diverse. This is called the random subspace method (Ho, 1998). As mentioned, this produces trees which are very diverse which translates into trees which are highly independent of each other. Because of the Jensen's inequality we know that the average of the errors of these trees predictions will be smaller or equal to the error of the average tree grown from that data set. Another way to look at it is to look at the Mean Squared Error and notice how it can be decomposed in bias and variance parts (this is related to an issue in supervised learning called the bias-variance tradeoff). Random forest achieves better precision by reducing variance through the averaging of the prediction of orthogonal trees. It should be noted that it inherits the bias of its trees, which is quite a discussed problem, check for example this question.\n",
    "\n",
    "https://stats.stackexchange.com/questions/77018/random-forest-is-it-a-boosting-algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In signal processing, independent component analysis (ICA) is a computational method for separating a multivariate signal into additive subcomponents. This is done by assuming that the subcomponents are non-Gaussian signals and that they are statistically independent from each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-24T20:31:16.840011Z",
     "start_time": "2018-02-24T20:30:51.400995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "displaying the exoplanet train set (10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>211.10</td>\n",
       "      <td>163.57</td>\n",
       "      <td>179.16</td>\n",
       "      <td>187.82</td>\n",
       "      <td>188.46</td>\n",
       "      <td>168.13</td>\n",
       "      <td>203.46</td>\n",
       "      <td>178.65</td>\n",
       "      <td>166.49</td>\n",
       "      <td>...</td>\n",
       "      <td>-98.45</td>\n",
       "      <td>30.34</td>\n",
       "      <td>30.34</td>\n",
       "      <td>29.62</td>\n",
       "      <td>28.80</td>\n",
       "      <td>19.27</td>\n",
       "      <td>-43.90</td>\n",
       "      <td>-41.63</td>\n",
       "      <td>-52.90</td>\n",
       "      <td>-16.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>9.34</td>\n",
       "      <td>49.96</td>\n",
       "      <td>33.30</td>\n",
       "      <td>9.63</td>\n",
       "      <td>37.64</td>\n",
       "      <td>20.85</td>\n",
       "      <td>4.54</td>\n",
       "      <td>22.42</td>\n",
       "      <td>10.11</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.56</td>\n",
       "      <td>9.93</td>\n",
       "      <td>9.93</td>\n",
       "      <td>23.50</td>\n",
       "      <td>5.28</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>10.90</td>\n",
       "      <td>-11.77</td>\n",
       "      <td>-9.25</td>\n",
       "      <td>-36.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>238.77</td>\n",
       "      <td>262.16</td>\n",
       "      <td>277.80</td>\n",
       "      <td>190.16</td>\n",
       "      <td>180.98</td>\n",
       "      <td>123.27</td>\n",
       "      <td>103.95</td>\n",
       "      <td>50.70</td>\n",
       "      <td>59.91</td>\n",
       "      <td>...</td>\n",
       "      <td>-72.48</td>\n",
       "      <td>31.77</td>\n",
       "      <td>31.77</td>\n",
       "      <td>53.48</td>\n",
       "      <td>27.88</td>\n",
       "      <td>95.30</td>\n",
       "      <td>48.86</td>\n",
       "      <td>-10.62</td>\n",
       "      <td>-112.02</td>\n",
       "      <td>-229.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>-103.54</td>\n",
       "      <td>-118.97</td>\n",
       "      <td>-108.93</td>\n",
       "      <td>-72.25</td>\n",
       "      <td>-61.46</td>\n",
       "      <td>-50.16</td>\n",
       "      <td>-20.61</td>\n",
       "      <td>-12.44</td>\n",
       "      <td>1.48</td>\n",
       "      <td>...</td>\n",
       "      <td>43.92</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.24</td>\n",
       "      <td>-7.45</td>\n",
       "      <td>-18.82</td>\n",
       "      <td>4.53</td>\n",
       "      <td>21.95</td>\n",
       "      <td>26.94</td>\n",
       "      <td>34.08</td>\n",
       "      <td>44.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>-265.91</td>\n",
       "      <td>-318.59</td>\n",
       "      <td>-335.66</td>\n",
       "      <td>-450.47</td>\n",
       "      <td>-453.09</td>\n",
       "      <td>-561.47</td>\n",
       "      <td>-606.03</td>\n",
       "      <td>-712.72</td>\n",
       "      <td>-685.97</td>\n",
       "      <td>...</td>\n",
       "      <td>3671.03</td>\n",
       "      <td>2249.28</td>\n",
       "      <td>2249.28</td>\n",
       "      <td>2437.78</td>\n",
       "      <td>2584.22</td>\n",
       "      <td>3162.53</td>\n",
       "      <td>3398.28</td>\n",
       "      <td>3648.34</td>\n",
       "      <td>3671.97</td>\n",
       "      <td>3781.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7  \\\n",
       "0      2    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n",
       "1      2   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
       "2      2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
       "3      2   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
       "4      2 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
       "5      2   211.10   163.57   179.16   187.82   188.46   168.13  203.46   \n",
       "6      2     9.34    49.96    33.30     9.63    37.64    20.85    4.54   \n",
       "7      2   238.77   262.16   277.80   190.16   180.98   123.27  103.95   \n",
       "8      2  -103.54  -118.97  -108.93   -72.25   -61.46   -50.16  -20.61   \n",
       "9      2  -265.91  -318.59  -335.66  -450.47  -453.09  -561.47 -606.03   \n",
       "\n",
       "    FLUX.8  FLUX.9    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0   -96.27  -79.89    ...         -78.07    -102.15    -102.15      25.13   \n",
       "1   -85.33  -83.97    ...          -3.28     -32.21     -32.21     -24.89   \n",
       "2   486.39  436.56    ...         -71.69      13.31      13.31     -29.89   \n",
       "3   311.31  312.42    ...           5.71      -3.73      -3.73      30.05   \n",
       "4 -1022.71 -989.57    ...        -594.37    -401.66    -401.66    -357.24   \n",
       "5   178.65  166.49    ...         -98.45      30.34      30.34      29.62   \n",
       "6    22.42   10.11    ...         -58.56       9.93       9.93      23.50   \n",
       "7    50.70   59.91    ...         -72.48      31.77      31.77      53.48   \n",
       "8   -12.44    1.48    ...          43.92       7.24       7.24      -7.45   \n",
       "9  -712.72 -685.97    ...        3671.03    2249.28    2249.28    2437.78   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "5      28.80      19.27     -43.90     -41.63     -52.90     -16.16  \n",
       "6       5.28      -0.44      10.90     -11.77      -9.25     -36.69  \n",
       "7      27.88      95.30      48.86     -10.62    -112.02    -229.92  \n",
       "8     -18.82       4.53      21.95      26.94      34.08      44.65  \n",
       "9    2584.22    3162.53    3398.28    3648.34    3671.97    3781.91  \n",
       "\n",
       "[10 rows x 3198 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "displaying the exoplanet test set (10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>119.88</td>\n",
       "      <td>100.21</td>\n",
       "      <td>86.46</td>\n",
       "      <td>48.68</td>\n",
       "      <td>46.12</td>\n",
       "      <td>39.39</td>\n",
       "      <td>18.57</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.63</td>\n",
       "      <td>...</td>\n",
       "      <td>14.52</td>\n",
       "      <td>19.29</td>\n",
       "      <td>14.44</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>13.33</td>\n",
       "      <td>45.50</td>\n",
       "      <td>31.93</td>\n",
       "      <td>35.78</td>\n",
       "      <td>269.43</td>\n",
       "      <td>57.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5736.59</td>\n",
       "      <td>5699.98</td>\n",
       "      <td>5717.16</td>\n",
       "      <td>5692.73</td>\n",
       "      <td>5663.83</td>\n",
       "      <td>5631.16</td>\n",
       "      <td>5626.39</td>\n",
       "      <td>5569.47</td>\n",
       "      <td>5550.44</td>\n",
       "      <td>...</td>\n",
       "      <td>-581.91</td>\n",
       "      <td>-984.09</td>\n",
       "      <td>-1230.89</td>\n",
       "      <td>-1600.45</td>\n",
       "      <td>-1824.53</td>\n",
       "      <td>-2061.17</td>\n",
       "      <td>-2265.98</td>\n",
       "      <td>-2366.19</td>\n",
       "      <td>-2294.86</td>\n",
       "      <td>-2034.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>844.48</td>\n",
       "      <td>817.49</td>\n",
       "      <td>770.07</td>\n",
       "      <td>675.01</td>\n",
       "      <td>605.52</td>\n",
       "      <td>499.45</td>\n",
       "      <td>440.77</td>\n",
       "      <td>362.95</td>\n",
       "      <td>207.27</td>\n",
       "      <td>...</td>\n",
       "      <td>17.82</td>\n",
       "      <td>-51.66</td>\n",
       "      <td>-48.29</td>\n",
       "      <td>-59.99</td>\n",
       "      <td>-82.10</td>\n",
       "      <td>-174.54</td>\n",
       "      <td>-95.23</td>\n",
       "      <td>-162.68</td>\n",
       "      <td>-36.79</td>\n",
       "      <td>30.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-826.00</td>\n",
       "      <td>-827.31</td>\n",
       "      <td>-846.12</td>\n",
       "      <td>-836.03</td>\n",
       "      <td>-745.50</td>\n",
       "      <td>-784.69</td>\n",
       "      <td>-791.22</td>\n",
       "      <td>-746.50</td>\n",
       "      <td>-709.53</td>\n",
       "      <td>...</td>\n",
       "      <td>122.34</td>\n",
       "      <td>93.03</td>\n",
       "      <td>93.03</td>\n",
       "      <td>68.81</td>\n",
       "      <td>9.81</td>\n",
       "      <td>20.75</td>\n",
       "      <td>20.25</td>\n",
       "      <td>-120.81</td>\n",
       "      <td>-257.56</td>\n",
       "      <td>-215.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-39.57</td>\n",
       "      <td>-15.88</td>\n",
       "      <td>-9.16</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-16.13</td>\n",
       "      <td>-24.05</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-45.20</td>\n",
       "      <td>-5.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.87</td>\n",
       "      <td>-61.85</td>\n",
       "      <td>-27.15</td>\n",
       "      <td>-21.18</td>\n",
       "      <td>-33.76</td>\n",
       "      <td>-85.34</td>\n",
       "      <td>-81.46</td>\n",
       "      <td>-61.98</td>\n",
       "      <td>-69.34</td>\n",
       "      <td>-17.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>14.28</td>\n",
       "      <td>10.63</td>\n",
       "      <td>14.56</td>\n",
       "      <td>12.42</td>\n",
       "      <td>12.07</td>\n",
       "      <td>12.92</td>\n",
       "      <td>12.27</td>\n",
       "      <td>3.19</td>\n",
       "      <td>8.47</td>\n",
       "      <td>...</td>\n",
       "      <td>3.86</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>-3.56</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>-7.18</td>\n",
       "      <td>-4.78</td>\n",
       "      <td>-4.34</td>\n",
       "      <td>7.67</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-7.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>-150.48</td>\n",
       "      <td>-141.72</td>\n",
       "      <td>-157.60</td>\n",
       "      <td>-184.60</td>\n",
       "      <td>-164.89</td>\n",
       "      <td>-173.87</td>\n",
       "      <td>-162.91</td>\n",
       "      <td>-167.04</td>\n",
       "      <td>-172.76</td>\n",
       "      <td>...</td>\n",
       "      <td>7.15</td>\n",
       "      <td>5.16</td>\n",
       "      <td>-9.08</td>\n",
       "      <td>-39.11</td>\n",
       "      <td>-32.31</td>\n",
       "      <td>-8.40</td>\n",
       "      <td>-16.80</td>\n",
       "      <td>-8.03</td>\n",
       "      <td>-12.73</td>\n",
       "      <td>-11.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>-10.06</td>\n",
       "      <td>-12.78</td>\n",
       "      <td>-13.16</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>-18.91</td>\n",
       "      <td>-20.33</td>\n",
       "      <td>-22.85</td>\n",
       "      <td>-19.17</td>\n",
       "      <td>-17.97</td>\n",
       "      <td>...</td>\n",
       "      <td>21.49</td>\n",
       "      <td>30.63</td>\n",
       "      <td>24.19</td>\n",
       "      <td>33.00</td>\n",
       "      <td>35.70</td>\n",
       "      <td>35.89</td>\n",
       "      <td>-33.44</td>\n",
       "      <td>-30.83</td>\n",
       "      <td>-33.00</td>\n",
       "      <td>-20.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>454.66</td>\n",
       "      <td>440.60</td>\n",
       "      <td>382.29</td>\n",
       "      <td>361.63</td>\n",
       "      <td>298.63</td>\n",
       "      <td>253.29</td>\n",
       "      <td>155.86</td>\n",
       "      <td>110.38</td>\n",
       "      <td>31.71</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.78</td>\n",
       "      <td>-61.64</td>\n",
       "      <td>-120.32</td>\n",
       "      <td>-65.39</td>\n",
       "      <td>-126.75</td>\n",
       "      <td>-78.18</td>\n",
       "      <td>-184.39</td>\n",
       "      <td>-142.31</td>\n",
       "      <td>-113.12</td>\n",
       "      <td>-111.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>187.40</td>\n",
       "      <td>209.60</td>\n",
       "      <td>199.91</td>\n",
       "      <td>179.62</td>\n",
       "      <td>171.21</td>\n",
       "      <td>161.84</td>\n",
       "      <td>163.02</td>\n",
       "      <td>171.61</td>\n",
       "      <td>113.53</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.75</td>\n",
       "      <td>-35.72</td>\n",
       "      <td>-21.93</td>\n",
       "      <td>-16.47</td>\n",
       "      <td>-21.84</td>\n",
       "      <td>-26.64</td>\n",
       "      <td>-13.90</td>\n",
       "      <td>17.03</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6   FLUX.7  \\\n",
       "0      2   119.88   100.21    86.46    48.68    46.12    39.39    18.57   \n",
       "1      2  5736.59  5699.98  5717.16  5692.73  5663.83  5631.16  5626.39   \n",
       "2      2   844.48   817.49   770.07   675.01   605.52   499.45   440.77   \n",
       "3      2  -826.00  -827.31  -846.12  -836.03  -745.50  -784.69  -791.22   \n",
       "4      2   -39.57   -15.88    -9.16    -6.37   -16.13   -24.05    -0.90   \n",
       "5      1    14.28    10.63    14.56    12.42    12.07    12.92    12.27   \n",
       "6      1  -150.48  -141.72  -157.60  -184.60  -164.89  -173.87  -162.91   \n",
       "7      1   -10.06   -12.78   -13.16    -9.81   -18.91   -20.33   -22.85   \n",
       "8      1   454.66   440.60   382.29   361.63   298.63   253.29   155.86   \n",
       "9      1   187.40   209.60   199.91   179.62   171.21   161.84   163.02   \n",
       "\n",
       "    FLUX.8   FLUX.9    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0     6.98     6.63    ...          14.52      19.29      14.44      -1.62   \n",
       "1  5569.47  5550.44    ...        -581.91    -984.09   -1230.89   -1600.45   \n",
       "2   362.95   207.27    ...          17.82     -51.66     -48.29     -59.99   \n",
       "3  -746.50  -709.53    ...         122.34      93.03      93.03      68.81   \n",
       "4   -45.20    -5.04    ...         -37.87     -61.85     -27.15     -21.18   \n",
       "5     3.19     8.47    ...           3.86      -4.06      -3.56      -1.13   \n",
       "6  -167.04  -172.76    ...           7.15       5.16      -9.08     -39.11   \n",
       "7   -19.17   -17.97    ...          21.49      30.63      24.19      33.00   \n",
       "8   110.38    31.71    ...         -56.78     -61.64    -120.32     -65.39   \n",
       "9   171.61   113.53    ...         -23.75     -35.72     -21.93     -16.47   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      13.33      45.50      31.93      35.78     269.43      57.72  \n",
       "1   -1824.53   -2061.17   -2265.98   -2366.19   -2294.86   -2034.72  \n",
       "2     -82.10    -174.54     -95.23    -162.68     -36.79      30.63  \n",
       "3       9.81      20.75      20.25    -120.81    -257.56    -215.41  \n",
       "4     -33.76     -85.34     -81.46     -61.98     -69.34     -17.84  \n",
       "5      -7.18      -4.78      -4.34       7.67      -0.33      -7.53  \n",
       "6     -32.31      -8.40     -16.80      -8.03     -12.73     -11.41  \n",
       "7      35.70      35.89     -33.44     -30.83     -33.00     -20.15  \n",
       "8    -126.75     -78.18    -184.39    -142.31    -113.12    -111.78  \n",
       "9     -21.84     -26.64     -13.90      17.03       4.36       2.91  \n",
       "\n",
       "[10 rows x 3198 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print('displaying the exoplanet train set (10)')\n",
    "exo_train = pd.read_csv('exoTrain.csv')\n",
    "display(exo_train[:10])\n",
    "print('displaying the exoplanet test set (10)')\n",
    "exo_test = pd.read_csv('exoTest.csv')\n",
    "display(exo_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-24T20:31:21.668039Z",
     "start_time": "2018-02-24T20:31:21.656038Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXOPLANET TRAIN dataset has 5087 data points with 3198 variables each.\n",
      "EXOPLANET TEST dataset has 570 data points with 3198 variables each.\n"
     ]
    }
   ],
   "source": [
    "print (\"EXOPLANET TRAIN dataset has {} data points with {} variables each.\".format(*exo_train.shape))\n",
    "\n",
    "# print (\"ATLAS TRAIN dataset has {} data points with {} variables each.\".format(train_data))\n",
    "print (\"EXOPLANET TEST dataset has {} data points with {} variables each.\".format(*exo_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-24T20:32:10.985967Z",
     "start_time": "2018-02-24T20:32:10.967967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING ACCURACY PERFOMANCE METRIC\n",
      "CREATED PERFOMANCE METRIC\n"
     ]
    }
   ],
   "source": [
    "print('CREATING ACCURACY PERFOMANCE METRIC')\n",
    "def performance_metric(y_true, y_predict):\n",
    "    from sklearn.metrics import accuracy_score,roc_curve, roc_auc_score\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    \n",
    "    # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    score = accuracy_score(y_true, y_predict)\n",
    "\n",
    "    # Return the score\n",
    "    return score\n",
    "print('CREATED PERFOMANCE METRIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-24T20:34:40.639032Z",
     "start_time": "2018-02-24T20:34:38.250614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting the RandomForestClassifier to a DECISIONTREECLASSIFIER \n",
      " \n",
      " \n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor,RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "# print('fitting the data to an ADABOOSTREGRESSOR \\n , params:= \\n n_estimators:[200,150,100,50,25,20,10,5], \\n learning_rate:[.7,.6,.5,.4,.25,.1], \\n LOSS: linear, square,exponential')\n",
    "print('fitting the RandomForestClassifier to a DECISIONTREECLASSIFIER \\n \\n \\n  ')\n",
    "def fit_model(x, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    cv_sets = ShuffleSplit(x.shape[0], n_iter = 15, test_size = 0.30, random_state =None)\n",
    "    \n",
    "    # TODO: Create a decision tree regressor object\n",
    "    classifier = RandomForestClassifier(DecisionTreeClassifier(criterion='entropy',max_depth=300,max_leaf_nodes=300,\n",
    "                                                              min_samples_leaf=12, min_samples_split=9))\n",
    "\n",
    "    # TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "    params = {'n_estimators':[150,75,50,5],\n",
    "          'verbose':[True],\n",
    "          'bootstrap':[True],\n",
    "            'n_jobs':[-1],\n",
    "              'oob_score':[True],\n",
    "              'max_depth':[300,40,30,20,10,5],\n",
    "              'max_features':['auto']\n",
    "             }\n",
    "\n",
    "    # TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "    # TODO: Create the grid search object\n",
    "    grid = GridSearchCV(classifier, params, scoring = scoring_fnc, cv = cv_sets)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(x, y)\n",
    "\n",
    "    # Return the optimal model after fitting the data\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-24T20:35:02.482666Z",
     "start_time": "2018-02-24T20:35:01.814677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LABEL\n",
      "3846      1\n",
      "461       1\n",
      "3314      1\n",
      "3308      1\n",
      "1280      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# ex_test = pd.read_csv('exoTest.csv')\n",
    "# ex_train = pd.read_csv('exoTrain.csv')\n",
    "label = exo_train[['LABEL']]\n",
    "new_label = exo_train.drop(['LABEL'], axis = 1)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test  = train_test_split(new_label,\n",
    "                                                 label,\n",
    "                                                 test_size=.3)\n",
    "print(y_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-24T20:35:04.368634Z",
     "start_time": "2018-02-24T20:35:04.336632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      FLUX.1  FLUX.2  FLUX.3  FLUX.4  FLUX.5  FLUX.6  FLUX.7  FLUX.8  FLUX.9  \\\n",
      "3846   16.46   35.27   53.93   61.25   66.21   86.89  107.61  136.11  159.24   \n",
      "461  -259.91 -264.97 -247.56 -234.96 -185.27 -196.22 -109.35 -126.72 -123.88   \n",
      "3314  -18.97  -16.58  -25.73  -23.34  -22.31  -21.93  -27.80  -32.03  -38.62   \n",
      "3308    4.83    9.09    4.63    1.87    8.60    8.80    1.88    8.12    6.19   \n",
      "1280  -22.56  -34.92  -28.64  -79.42  -28.08  -81.64  -35.17    1.11  -11.45   \n",
      "\n",
      "      FLUX.10    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
      "3846   198.06    ...          49.91      42.85      28.09      80.68   \n",
      "461   -135.72    ...         -52.05     -97.82     -92.02     -59.57   \n",
      "3314   -39.89    ...          61.49      72.30      78.54      82.62   \n",
      "3308    -0.69    ...           6.76       5.48       4.58       5.52   \n",
      "1280   -25.14    ...          34.41      21.86      54.02      37.97   \n",
      "\n",
      "      FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
      "3846     137.07      98.66     -21.63     -66.79     -58.71     -19.43  \n",
      "461      -28.19       2.86      -9.99      34.68      43.54      36.98  \n",
      "3314      78.56      81.60      69.22      71.01      72.27      59.73  \n",
      "3308      12.73      10.00       8.49       8.54       2.22       6.12  \n",
      "1280      47.75      84.52      28.31      -2.17     -20.34      -9.45  \n",
      "\n",
      "[5 rows x 3197 columns]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-24T20:35:05.124605Z",
     "start_time": "2018-02-24T20:35:05.109627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LABEL\n",
      "3098      1\n",
      "4090      1\n",
      "3172      1\n",
      "759       1\n",
      "1816      1\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-24T20:35:06.240598Z",
     "start_time": "2018-02-24T20:35:06.202535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      FLUX.1  FLUX.2  FLUX.3  FLUX.4  FLUX.5  FLUX.6  FLUX.7  FLUX.8  FLUX.9  \\\n",
      "3098 -194.00 -176.47 -190.65 -168.86 -156.31 -125.26  -94.34  -88.17  -82.01   \n",
      "4090  206.19   75.19   43.56 -113.12 -136.94 -211.31  -96.56   13.56   50.00   \n",
      "3172  -56.85  -46.84  -52.29  -34.79  -35.51  -24.62  -28.87  -17.09  -15.52   \n",
      "759   -28.46  -33.22  -22.07  -20.92  -10.48  -14.78  -16.82  -17.47   -4.00   \n",
      "1816   -0.96   -1.91   -0.84   -4.70   -4.36    1.27   -9.18   -4.99   -0.89   \n",
      "\n",
      "      FLUX.10    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
      "3098   -61.29    ...         -33.48      23.55      11.22      12.89   \n",
      "4090    41.75    ...          89.75      88.13     131.88    -100.75   \n",
      "3172     9.03    ...           2.61      24.16       6.04      37.17   \n",
      "759     -7.63    ...          12.70      14.45       6.44      -0.36   \n",
      "1816    -5.24    ...           7.60      -0.23      -3.25       4.11   \n",
      "\n",
      "      FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
      "3098      47.30      41.75      -6.26      -0.04       9.41      18.39  \n",
      "4090      -8.50     -95.44      40.56      72.32     126.25     145.69  \n",
      "3172      23.96      26.83       2.70      -3.49     -10.89      -4.31  \n",
      "759       14.86      13.56      12.70       5.69       8.85      41.89  \n",
      "1816       2.02      -2.09       0.94       3.77       5.41       2.83  \n",
      "\n",
      "[5 rows x 3197 columns]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-24T20:35:34.554104Z",
     "start_time": "2018-02-24T20:35:07.238581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COFFE BREAK \n",
      " FITTING THE GRID TO THE PARAMETERS.. \n",
      " NAPS ARE NICE TOO ^__^\n",
      "eta 1 hour 15 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-617c3feef0b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'eta 1 hour 15 minutes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'BEEP!! BEEP!!! BEEEEEPPP!!!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-3a223ad69ddc>\u001b[0m in \u001b[0;36mfit_model\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# Fit the grid search object to the data to compute the optimal model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# Return the optimal model after fitting the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m         \"\"\"\n\u001b[1;32m--> 838\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 574\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m                 for train, test in cv)\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[0;32m   1673\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1675\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1677\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moob_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_oob_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;31m# Decapsulate classes_ attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_set_oob_score\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    440\u001b[0m             unsampled_indices = _generate_unsampled_indices(\n\u001b[0;32m    441\u001b[0m                 estimator.random_state, n_samples)\n\u001b[1;32m--> 442\u001b[1;33m             p_estimator = estimator.predict_proba(X[unsampled_indices, :],\n\u001b[0m\u001b[0;32m    443\u001b[0m                                                   check_input=False)\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('COFFE BREAK \\n FITTING THE GRID TO THE PARAMETERS.. \\n NAPS ARE NICE TOO ^__^')\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "print('eta 1 hour 15 minutes')\n",
    "clf = fit_model(x_train, y_train.values.ravel())\n",
    "print('BEEP!! BEEP!!! BEEEEEPPP!!!')\n",
    "\n",
    "print('eta 1 hour 15 minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-14T19:46:13.612197Z",
     "start_time": "2018-02-14T19:46:13.586199Z"
    }
   },
   "source": [
    "Definition 2.1  The margin function for a random forest is\n",
    "         mr(X,Y) = PΘ(h(X,Θ)=Y)−maxj≠Y PΘ(h(X,Θ)= j)     (2)\n",
    "and the strength of the set of classifiers  {h(x,Θ)} is\n",
    "           s=E\n",
    "X,Y\n",
    "mr(X,Y)     \n",
    "\n",
    "https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf\n",
    "\n",
    "\n",
    "i) Its accuracy is as good as AdaBoost and sometimes better.\n",
    "ii) It's relatively robust to outliers and noise.\n",
    "iii) It's faster than bagging or boosting. \n",
    "iv) It gives useful internal estimates of error, strength, correlation and variable importance. \n",
    "v) It's simple and easily parallelized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition 1.1  A random forest is a classifier consisting of a collection of treestructured classifiers  {h(x,Θk), k=1,...} where the {Θk} are independent identically distributed random vectors and each tree casts a unit vote for the most popular class at input  x .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# entropy = -sum(i) -(Pri)log2(Pri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-02-15T19:05:08.384Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA, PCA\n",
    "print('transforming the ADABOOSTCLASSIFIER DATA')\n",
    "ADB_CLF= AdaBoostClassifier((clf), n_estimators = 150, learning_rate = .4)\n",
    "ADB_CLF.fit(x_train,y_train)\n",
    "\n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-14T21:39:10.543061Z",
     "start_time": "2018-02-14T21:39:09.806160Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=40, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
      "            oob_score=True, random_state=None, verbose=True,\n",
      "            warm_start=False),\n",
      "          learning_rate=0.4, n_estimators=150, random_state=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9927963326784545"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ADB_CLF)\n",
    "ADB_CLF.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-14T21:40:09.208929Z",
     "start_time": "2018-02-14T21:40:08.760938Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1527 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     1\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    1\n",
       "14    1\n",
       "15    1\n",
       "16    1\n",
       "17    1\n",
       "18    1\n",
       "19    1\n",
       "20    1\n",
       "21    1\n",
       "22    1\n",
       "23    1\n",
       "24    1\n",
       "25    1\n",
       "26    1\n",
       "27    1\n",
       "28    1\n",
       "29    1\n",
       "...  ..\n",
       "1497  1\n",
       "1498  1\n",
       "1499  1\n",
       "1500  1\n",
       "1501  1\n",
       "1502  1\n",
       "1503  1\n",
       "1504  1\n",
       "1505  1\n",
       "1506  1\n",
       "1507  1\n",
       "1508  1\n",
       "1509  1\n",
       "1510  1\n",
       "1511  1\n",
       "1512  1\n",
       "1513  1\n",
       "1514  1\n",
       "1515  1\n",
       "1516  1\n",
       "1517  1\n",
       "1518  1\n",
       "1519  1\n",
       "1520  1\n",
       "1521  1\n",
       "1522  1\n",
       "1523  1\n",
       "1524  1\n",
       "1525  1\n",
       "1526  1\n",
       "\n",
       "[1527 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ADB_CLF.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-14T21:40:11.357316Z",
     "start_time": "2018-02-14T21:40:11.085171Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<1527x2900 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 493517 stored elements in Compressed Sparse Row format>,\n",
       " array([   0,   57,  110,  183,  238,  297,  362,  425,  478,  533,  588,\n",
       "         645,  698,  745,  814,  865,  922,  959, 1024, 1083, 1130, 1201,\n",
       "        1260, 1315, 1370, 1435, 1490, 1551, 1614, 1685, 1758, 1819, 1888,\n",
       "        1929, 1992, 2049, 2106, 2149, 2202, 2263, 2324, 2379, 2446, 2505,\n",
       "        2546, 2621, 2670, 2731, 2786, 2851, 2900], dtype=int32))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(clf.decision_path(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-14T21:40:14.085859Z",
     "start_time": "2018-02-14T21:40:13.661866Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-25.088454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-25.326376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-25.326376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-14.229003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-25.326376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-25.326376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-25.088454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-14.133254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-25.326376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-25.326387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-14.125940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-14.133254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-14.609098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-3.653898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-13.738046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-13.975968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-3.653898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-25.326387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>-25.326387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>-14.229003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>-25.088454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>-25.326387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>-25.326376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>-14.609098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>-24.946281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>-25.326387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>-24.843218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>-25.326376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>-14.371176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>-25.326387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>-25.326376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>-14.229003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>-14.133254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>-36.043653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>-14.609098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1527 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0    -25.088454\n",
       "1    -25.326376\n",
       "2    -25.326376\n",
       "3    -14.229003\n",
       "4    -36.043653\n",
       "5    -25.326376\n",
       "6    -36.043653\n",
       "7    -25.326376\n",
       "8    -25.088454\n",
       "9    -14.133254\n",
       "10   -36.043653\n",
       "11   -36.043653\n",
       "12   -25.326376\n",
       "13   -25.326387\n",
       "14   -36.043653\n",
       "15   -36.043653\n",
       "16   -36.043653\n",
       "17   -14.125940\n",
       "18   -14.133254\n",
       "19   -36.043653\n",
       "20   -14.609098\n",
       "21    -3.653898\n",
       "22   -13.738046\n",
       "23   -36.043653\n",
       "24   -13.975968\n",
       "25   -36.043653\n",
       "26   -36.043653\n",
       "27    -3.653898\n",
       "28   -25.326387\n",
       "29   -36.043653\n",
       "...         ...\n",
       "1497 -25.326387\n",
       "1498 -14.229003\n",
       "1499 -25.088454\n",
       "1500 -25.326387\n",
       "1501 -36.043653\n",
       "1502 -36.043653\n",
       "1503 -36.043653\n",
       "1504 -36.043653\n",
       "1505 -36.043653\n",
       "1506 -25.326376\n",
       "1507 -36.043653\n",
       "1508 -14.609098\n",
       "1509 -36.043653\n",
       "1510 -24.946281\n",
       "1511 -25.326387\n",
       "1512 -36.043653\n",
       "1513 -36.043653\n",
       "1514 -24.843218\n",
       "1515 -36.043653\n",
       "1516 -36.043653\n",
       "1517 -25.326376\n",
       "1518 -14.371176\n",
       "1519 -25.326387\n",
       "1520 -25.326376\n",
       "1521 -14.229003\n",
       "1522 -36.043653\n",
       "1523 -14.133254\n",
       "1524 -36.043653\n",
       "1525 -36.043653\n",
       "1526 -14.609098\n",
       "\n",
       "[1527 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ADB_CLF.decision_function(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T18:08:44.523280Z",
     "start_time": "2018-02-13T18:08:44.507751Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-14T21:40:19.326142Z",
     "start_time": "2018-02-14T21:40:19.314117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM INDEPENDENT/PRINCIPAL COMPONENT ANALYSIS\n"
     ]
    }
   ],
   "source": [
    "print('RANDOM INDEPENDENT/PRINCIPAL COMPONENT ANALYSIS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-14T22:09:39.570174Z",
     "start_time": "2018-02-14T22:09:39.542181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICA CLF\n",
      "FastICA(algorithm='deflation', fun='logcosh', fun_args={'alpha': 1.7},\n",
      "    max_iter=500, n_components=2, random_state=111111, tol=0.0025,\n",
      "    w_init=None, whiten=True)\n",
      "PCA CLF\n",
      "PCA(copy=True, iterated_power='auto', n_components=2, random_state=111111,\n",
      "  svd_solver='arpack', tol=0.0025, whiten=True)\n"
     ]
    }
   ],
   "source": [
    "ICA1_CLF = FastICA(n_components= 2, algorithm='deflation', whiten=True, fun='logcosh', fun_args= {'alpha' :1.7}, max_iter=500, tol=0.0025, random_state=111111)\n",
    "\n",
    "PCA_CLF = PCA(n_components=2,whiten=True,tol=.0025,random_state=111111, svd_solver ='arpack')\n",
    "print('ICA CLF')\n",
    "# ICA.fit(x_train) #y ignored\n",
    "print(ICA1_CLF)\n",
    "\n",
    "print('PCA CLF')\n",
    "print(PCA_CLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-14T22:10:28.972853Z",
     "start_time": "2018-02-14T22:09:41.676289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming the Ica data\n",
      "transforming the Pca data\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "print('transforming the Ica data')\n",
    "ICA_CLF_T = ICA1_CLF.fit_transform(x_train)\n",
    "print('transforming the Pca data')\n",
    "PCA_CLF_T = PCA_CLF.fit_transform(x_train)\n",
    "\n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-14T22:10:38.690182Z",
     "start_time": "2018-02-14T22:10:38.334201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.467287e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.772522e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.467225e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.774768e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.258460e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.160430e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.081669e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.879499e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.628546e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.125535e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.485557e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.062199e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.500628e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.619327e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.039286e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.690460e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.260640e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.835076e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7.168889e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.297435e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.308837e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.148431e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.280272e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>1.371870e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>6.083043e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>1.974101e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>6.006689e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>1.700911e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>8.419186e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>2.638080e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>1.655592e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3176</th>\n",
       "      <td>1.324876e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3177</th>\n",
       "      <td>1.028218e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>2.053089e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>2.066374e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>1.594975e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>6.456961e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>7.515714e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>3.257992e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>1.190259e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>1.037190e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>1.200115e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>1.271965e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>2.168289e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>5.061729e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>2.665618e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>1.512543e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>2.392487e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>1.052065e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>5.287034e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>2.748768e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3197 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "0     0.000000e+00\n",
       "1     0.000000e+00\n",
       "2     4.467287e-04\n",
       "3     1.772522e-04\n",
       "4     1.467225e-05\n",
       "5     5.774768e-05\n",
       "6     0.000000e+00\n",
       "7     2.258460e-04\n",
       "8     4.160430e-07\n",
       "9     0.000000e+00\n",
       "10    7.081669e-04\n",
       "11    6.879499e-05\n",
       "12    3.628546e-04\n",
       "13    1.125535e-04\n",
       "14    8.485557e-05\n",
       "15    2.062199e-04\n",
       "16    0.000000e+00\n",
       "17    2.500628e-04\n",
       "18    2.619327e-04\n",
       "19    9.039286e-05\n",
       "20    6.690460e-04\n",
       "21    1.260640e-07\n",
       "22    0.000000e+00\n",
       "23    5.835076e-04\n",
       "24    7.168889e-05\n",
       "25    0.000000e+00\n",
       "26    4.297435e-04\n",
       "27    1.308837e-03\n",
       "28    2.148431e-04\n",
       "29    1.280272e-06\n",
       "...            ...\n",
       "3167  0.000000e+00\n",
       "3168  1.371870e-06\n",
       "3169  6.083043e-04\n",
       "3170  1.974101e-04\n",
       "3171  6.006689e-04\n",
       "3172  1.700911e-06\n",
       "3173  8.419186e-04\n",
       "3174  2.638080e-10\n",
       "3175  1.655592e-07\n",
       "3176  1.324876e-03\n",
       "3177  1.028218e-04\n",
       "3178  2.053089e-03\n",
       "3179  2.066374e-04\n",
       "3180  1.594975e-14\n",
       "3181  6.456961e-04\n",
       "3182  7.515714e-04\n",
       "3183  3.257992e-04\n",
       "3184  1.190259e-03\n",
       "3185  1.037190e-03\n",
       "3186  1.200115e-03\n",
       "3187  1.271965e-05\n",
       "3188  2.168289e-04\n",
       "3189  5.061729e-07\n",
       "3190  2.665618e-04\n",
       "3191  1.512543e-04\n",
       "3192  2.392487e-04\n",
       "3193  1.052065e-03\n",
       "3194  5.287034e-04\n",
       "3195  0.000000e+00\n",
       "3196  2.748768e-05\n",
       "\n",
       "[3197 rows x 1 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ADB_CLF.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-14T22:10:41.254176Z",
     "start_time": "2018-02-14T22:10:40.827146Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9927963326784545"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ADB_CLF.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-14T22:10:45.486190Z",
     "start_time": "2018-02-14T22:10:42.951029Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(ADB_CLF.score(x_test[9:10],y_test[9:10]))\n",
    "print(ADB_CLF.score(x_test[19:20],y_test[19:20]))\n",
    "print(ADB_CLF.score(x_test[200:201],y_test[200:201]))\n",
    "print(ADB_CLF.score(x_test[400:401],y_test[400:401]))\n",
    "print(ADB_CLF.score(x_test[500:501],y_test[500:501]))\n",
    "print(ADB_CLF.score(x_test[450:451],y_test[450:451]))\n",
    "print(ADB_CLF.score(x_test[50:51],y_test[50:51]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-14T22:10:49.953260Z",
     "start_time": "2018-02-14T22:10:48.683858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING VISUAL\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x211110c82e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "print('CREATING VISUAL')\n",
    "\n",
    "models = [ICA1_CLF.mixing_, exo_train, ICA_CLF_T,PCA_CLF_T]\n",
    "names = ['Observations (mixed signal)',\n",
    "         'True Sources',\n",
    "         'ICA recovered signals',\n",
    "        'PCA recovered signals']\n",
    "colors = ['yellow', 'steelblue', \n",
    "         'black','green',\n",
    "         'red']\n",
    "\n",
    "for ii, (model, name) in enumerate(zip(models, names), 1):\n",
    "    plt.subplot(4, 1, ii)\n",
    "    plt.title(name)\n",
    "    plt.legend(models)\n",
    "    for sig, color in zip(model.T, colors):\n",
    "        plt.plot(sig, color=color)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(0.09, 0.04, 0.94, 0.94, 0.26, 0.46)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-15T04:17:08.114225Z",
     "start_time": "2018-02-15T04:17:06.962277Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "c of shape (3560, 1) not acceptable as a color sequence for x with size 3197, y with size 3197",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mrgba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_colors_full_map\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Not in cache, or unhashable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('LABEL', None)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[0;32m   3982\u001b[0m                 \u001b[1;31m# must be acceptable as PathCollection facecolors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3983\u001b[1;33m                 \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_rgba_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3984\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36mto_rgba_array\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Not in cache, or unhashable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[0mrgba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[1;34m(c, alpha)\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid RGBA argument: {!r}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_c\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m     \u001b[1;31m# tuple color.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid RGBA argument: 'LABEL'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-3e39da39de80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Plot the training points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m plt.scatter(x_min, x_max, c=y_train, cmap=plt.cm.Set1,\n\u001b[1;32m---> 10\u001b[1;33m             edgecolor='k')\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Sepal length'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Sepal width'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, hold, data, **kwargs)\u001b[0m\n\u001b[0;32m   3376\u001b[0m                          \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3377\u001b[0m                          \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3378\u001b[1;33m                          edgecolors=edgecolors, data=data, **kwargs)\n\u001b[0m\u001b[0;32m   3379\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3380\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1715\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[0;32m   1716\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1717\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1718\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[0;32m   3986\u001b[0m                 msg = (\"c of shape {0} not acceptable as a color sequence \"\n\u001b[0;32m   3987\u001b[0m                        \"for x with size {1}, y with size {2}\")\n\u001b[1;32m-> 3988\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3989\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3990\u001b[0m             \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# use cmap, norm after collection is created\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: c of shape (3560, 1) not acceptable as a color sequence for x with size 3197, y with size 3197"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x211290f4278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "plt.figure(2, figsize=(8, 6))\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "x_min, x_max = np.min(x_train), np.max(x_train)\n",
    "y_min, y_max = np.min(y_train), np.max(y_train)\n",
    "# Plot the training points\n",
    "plt.scatter(x_min, x_max, c=y_train, cmap=plt.cm.Set1,\n",
    "            edgecolor='k')\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "# To getter a better understanding of interaction of the dimensions\n",
    "# plot the first three PCA dimensions\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "ax = Axes3D(fig, elev=-150, azim=110)\n",
    "\n",
    "ax.scatter(x_train, PCA_CLF_T,\n",
    "           cmap=plt.cm.Set1, edgecolor='k')\n",
    "ax.set_title(\"First three PCA directions\")\n",
    "ax.set_xlabel(\"1st eigenvector\")\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(\"2nd eigenvector\")\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(\"3rd eigenvector\")\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T04:37:30.136574Z",
     "start_time": "2018-02-08T04:37:30.019075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting the data to a  GradientBoostingClassifier \n",
      " , params:= \n",
      " n_estimators:[200,150,100,50,25,20,10,5], \n",
      " learning_rate:[.7,.6,.5,.4,.25,.1], \n",
      " LOSS: deviance, exponential \n",
      " criterion = friedman_mse,mse,mae\n"
     ]
    }
   ],
   "source": [
    "        from sklearn.ensemble import AdaBoostRegressor, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "print('fitting the data to a  GradientBoostingClassifier \\n , params:= \\n n_estimators:[200,150,100,50,25,20,10,5], \\n learning_rate:[.7,.6,.5,.4,.25,.1], \\n LOSS: deviance, exponential \\n criterion = friedman_mse,mse,mae')\n",
    "\n",
    "def clf_fit_model(x, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    cv_sets = ShuffleSplit(x.shape[0], n_iter = 15, test_size = 0.20, random_state =None)\n",
    "    params = {'n_estimators':[200,150,100,50,25,20,10,5],\n",
    "          'learning_rate':[.7,.6,.5,.4,.25,.1],\n",
    "          'random_state':[1222,164]\n",
    "          }\n",
    "    # TODO: Create a decision tree regressor object\n",
    "    classifier = AdaBoostClassifier(DecisionTreeClassifier(criterion='gini',max_depth=300,max_leaf_nodes=300, min_samples_leaf=12, min_samples_split=9))\n",
    "\n",
    "#     # TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "#     params = {'n_estimators':[200,150,100,50,25,20,10,5],\n",
    "#           'learning_rate':[.7,.6,.5,.4,.25,.1],\n",
    "#           'loss':['linear','square','exponential'],\n",
    "#              }\n",
    "\n",
    "    # TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "    # TODO: Create the grid search object\n",
    "    grid = GridSearchCV(classifier, params, scoring = scoring_fnc, cv = cv_sets)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(x, y)\n",
    "\n",
    "    # Return the optimal model after fitting the data\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T04:48:39.052824Z",
     "start_time": "2018-02-08T04:37:31.489050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COFFE BREAK \n",
      " FITTING THE GRID TO THE PARAMETERS.. \n",
      " NAPS ARE NICE TOO ^__^\n",
      "BEEP!! BEEP!!! BEEEEEPPP!!!\n"
     ]
    }
   ],
   "source": [
    "print('COFFE BREAK \\n FITTING THE GRID TO THE PARAMETERS.. \\n NAPS ARE NICE TOO ^__^')\n",
    "clf = clf_fit_model(x_train, y_train.ravel())\n",
    "print('BEEP!! BEEP!!! BEEEEEPPP!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RANDOM I.C. ANALYSIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICA1_CLF = FastICA(n_components= 4, algorithm='deflation', whiten=True, fun='logcosh', fun_args= {'alpha' :1.5}, max_iter=500, tol=0.0025, random_state=111111)\n",
    "ICA1_CLF.fit(x_train)\n",
    "print('ICA CLF')\n",
    "# ICA.fit(x_train) #y ignored\n",
    "print(ICA1_CLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('transforming the ica,pca data')\n",
    "ICA_CLF_T = ICA.fit_transform(x_train)\n",
    "\n",
    "\n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CREATING VISUAL')\n",
    "\n",
    "models = [ICA1.mixing_, x_train, ICA_CLF_T]\n",
    "names = ['Observations (mixed signal)',\n",
    "         'True Sources',\n",
    "         'ICA recovered signals']\n",
    "colors = ['red', 'steelblue', 'orange','purple',\n",
    "         'green']\n",
    "\n",
    "for ii, (model, name) in enumerate(zip(models, names), 1):\n",
    "    plt.subplot(4, 1, ii)\n",
    "    plt.title(name)\n",
    "    plt.legend(models)\n",
    "    for sig, color in zip(model.T, colors):\n",
    "        plt.plot(sig, color=color)\n",
    "\n",
    "\n",
    "# plt.subplots_adjust(0.09, 0.04, 0.94, 0.94, 0.26, 0.46)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CREATING VISUAL')\n",
    "\n",
    "models = [ICA1.mixing_, x_train, ICA_CLF_T]\n",
    "names = ['Observations (mixed signal)',\n",
    "         'True Sources',\n",
    "         'ICA recovered signals']\n",
    "colors = ['red', 'steelblue', 'orange','purple',\n",
    "         'green']\n",
    "\n",
    "for ii, (model, name) in enumerate(zip(models, names), 1):\n",
    "    plt.subplot(4, 1, ii)\n",
    "    plt.title(name)\n",
    "    plt.legend(models)\n",
    "    for sig, color in zip(model.T, colors):\n",
    "        plt.plot(sig, color=color)\n",
    "\n",
    "\n",
    "# plt.subplots_adjust(0.09, 0.04, 0.94, 0.94, 0.26, 0.46)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T06:53:07.381890Z",
     "start_time": "2018-02-08T06:53:07.364408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape[0])\n",
    "print(y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T06:55:50.274114Z",
     "start_time": "2018-02-08T06:55:50.202116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y TRAIN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0     0.0\n",
       "1     0.0\n",
       "2     0.0\n",
       "3     0.0\n",
       "4     0.0\n",
       "5     0.0\n",
       "6     0.0\n",
       "7     0.0\n",
       "8     0.0\n",
       "9     0.0\n",
       "10    0.0\n",
       "11    0.0\n",
       "12    0.0\n",
       "13    0.0\n",
       "14    0.0\n",
       "15    0.0\n",
       "16    0.0\n",
       "17    0.0\n",
       "18    0.0\n",
       "19    0.0\n",
       "20    0.0\n",
       "21    0.0\n",
       "22    0.0\n",
       "23    0.0\n",
       "24    0.0\n",
       "25    0.0\n",
       "26    0.0\n",
       "27    0.0\n",
       "28    0.0\n",
       "29    0.0\n",
       "...   ...\n",
       "2970  0.0\n",
       "2971  0.0\n",
       "2972  0.0\n",
       "2973  0.0\n",
       "2974  0.0\n",
       "2975  0.0\n",
       "2976  0.0\n",
       "2977  0.0\n",
       "2978  0.0\n",
       "2979  0.0\n",
       "2980  0.0\n",
       "2981  0.0\n",
       "2982  0.0\n",
       "2983  0.0\n",
       "2984  0.0\n",
       "2985  0.0\n",
       "2986  0.0\n",
       "2987  0.0\n",
       "2988  0.0\n",
       "2989  0.0\n",
       "2990  0.0\n",
       "2991  0.0\n",
       "2992  0.0\n",
       "2993  0.0\n",
       "2994  0.0\n",
       "2995  0.0\n",
       "2996  0.0\n",
       "2997  0.0\n",
       "2998  0.0\n",
       "2999  0.0\n",
       "\n",
       "[3000 rows x 1 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_train)\n",
    "print('Y TRAIN')\n",
    "pd.DataFrame(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T04:40:53.288408Z",
     "start_time": "2018-02-06T04:40:53.272407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method RegressorMixin.score of AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mae', max_depth=300, max_features=1008,\n",
      "           max_leaf_nodes=300, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=12,\n",
      "           min_samples_split=9, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best'),\n",
      "         learning_rate=0.7, loss='linear', n_estimators=200,\n",
      "         random_state=None)>\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(reg.score)\n",
    "\n",
    "print(reg.estimator_errors_)\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(reg.score(x_test,y_test))\n",
    "print(reg.predict(x_test))\n",
    "print('X TEST')\n",
    "display(x_test[:5])\n",
    "print('Y TEST')\n",
    "display(y_test[:5])\n",
    "print('X TRAIN')\n",
    "display(x_train[:5])\n",
    "print('Y TRAIN')\n",
    "display(y_train[:5])\n",
    "print(x_train.shape[0])\n",
    "print(y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T17:46:04.100217Z",
     "start_time": "2018-02-07T17:46:01.380574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LETS CHECK OUT THE INDEPENDENT COMPONENT ANALYSIS\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "print('LETS CHECK OUT THE INDEPENDENT COMPONENT ANALYSIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T17:56:56.918882Z",
     "start_time": "2018-02-07T17:55:16.728331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastICA(algorithm='deflation', fun='logcosh', fun_args={'alpha': 1.5},\n",
      "    max_iter=500, n_components=4, random_state=None, tol=0.0025,\n",
      "    w_init=None, whiten=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "ICA = FastICA(n_components= 4, algorithm='deflation', whiten=True, fun='logcosh', fun_args= {'alpha' :1.5}, max_iter=500, tol=0.0025, random_state=None)\n",
    "print(ICA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(copy=True, iterated_power=500, n_components=4, random_state=None,\n",
      "  svd_solver='randomized', tol=0.0025, whiten=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "PCA = PCA(n_components= 4, svd_solver='randomized', whiten=True, tol=0.0025, iterated_power=500)\n",
    "print(PCA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T18:22:23.387205Z",
     "start_time": "2018-02-07T18:21:19.505327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FITTING/transforming the ica,pca data\n",
      "ICA\n",
      "STARTING PCA\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "print('FITTING/transforming the ica,pca data')\n",
    "print('ICA')\n",
    "ICA = ICA.fit_transform(x_train)\n",
    "print('STARTING PCA')\n",
    "PCA = PCA.fit_transform(x_train)\n",
    "\n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T18:49:36.540566Z",
     "start_time": "2018-02-07T18:48:30.010628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refitting to create the visual\n",
      "FastICA(algorithm='deflation', fun='logcosh', fun_args={'alpha': 1.5},\n",
      "    max_iter=500, n_components=4, random_state=11111, tol=0.0025,\n",
      "    w_init=None, whiten=True)\n",
      "making vis\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23500317e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('refitting to create the visual')\n",
    "from sklearn.decomposition import FastICA\n",
    "ICA1= FastICA(n_components= 4, algorithm='deflation', whiten=True, fun='logcosh', fun_args= {'alpha' :1.5}, max_iter=500, tol=0.0025, random_state=11111)\n",
    "print(ICA1)\n",
    "ICA1.fit(x_train)\n",
    "\n",
    "\n",
    "print('making vis')\n",
    "\n",
    "models = [ICA1.mixing_, x_train, ICA, PCA]\n",
    "names = ['Observations (mixed signal)',\n",
    "         'True Sources',\n",
    "         'ICA recovered signals',\n",
    "         'PCA recovered signals']\n",
    "colors = ['red', 'steelblue', 'orange']\n",
    "\n",
    "for ii, (model, name) in enumerate(zip(models, names), 1):\n",
    "    plt.subplot(4, 1, ii)\n",
    "    plt.title(name)\n",
    "    plt.legend(models)\n",
    "    for sig, color in zip(model.T, colors):\n",
    "        plt.plot(sig, color=color)\n",
    "\n",
    "\n",
    "# plt.subplots_adjust(0.09, 0.04, 0.94, 0.94, 0.26, 0.46)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T18:25:09.311545Z",
     "start_time": "2018-02-07T18:25:09.251047Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540939.044324</td>\n",
       "      <td>74114.486668</td>\n",
       "      <td>1.263286e+06</td>\n",
       "      <td>485274.742942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536382.454536</td>\n",
       "      <td>68441.372560</td>\n",
       "      <td>1.283827e+06</td>\n",
       "      <td>483969.608486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>520182.714285</td>\n",
       "      <td>56714.405780</td>\n",
       "      <td>1.331607e+06</td>\n",
       "      <td>427112.547630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>486431.761113</td>\n",
       "      <td>48242.362221</td>\n",
       "      <td>1.428792e+06</td>\n",
       "      <td>307522.893686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>440245.130499</td>\n",
       "      <td>34537.029177</td>\n",
       "      <td>1.537833e+06</td>\n",
       "      <td>137166.671000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>398319.292181</td>\n",
       "      <td>20745.263023</td>\n",
       "      <td>1.621320e+06</td>\n",
       "      <td>-31864.918446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>355245.285097</td>\n",
       "      <td>4320.396100</td>\n",
       "      <td>1.629135e+06</td>\n",
       "      <td>-117645.717741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>352410.378531</td>\n",
       "      <td>-5128.032271</td>\n",
       "      <td>1.545080e+06</td>\n",
       "      <td>-40748.896876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>367237.354002</td>\n",
       "      <td>-14333.459813</td>\n",
       "      <td>1.394869e+06</td>\n",
       "      <td>106217.093674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>385502.514965</td>\n",
       "      <td>-22058.060969</td>\n",
       "      <td>1.237396e+06</td>\n",
       "      <td>251204.074143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>375887.620113</td>\n",
       "      <td>-35186.117668</td>\n",
       "      <td>1.103805e+06</td>\n",
       "      <td>362896.105609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>355873.918123</td>\n",
       "      <td>-49310.287777</td>\n",
       "      <td>9.931661e+05</td>\n",
       "      <td>388316.332034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>320070.053228</td>\n",
       "      <td>-66305.355608</td>\n",
       "      <td>9.265297e+05</td>\n",
       "      <td>379025.311114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>294253.966470</td>\n",
       "      <td>-80961.821221</td>\n",
       "      <td>8.465183e+05</td>\n",
       "      <td>355049.076039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>261176.688890</td>\n",
       "      <td>-94335.128250</td>\n",
       "      <td>7.787097e+05</td>\n",
       "      <td>334956.187817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>220939.469442</td>\n",
       "      <td>-107339.238086</td>\n",
       "      <td>7.230176e+05</td>\n",
       "      <td>326678.561463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>187404.753201</td>\n",
       "      <td>-119548.387660</td>\n",
       "      <td>6.675592e+05</td>\n",
       "      <td>312712.572966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>154012.988096</td>\n",
       "      <td>-130805.384930</td>\n",
       "      <td>6.252785e+05</td>\n",
       "      <td>308959.744079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>146434.720910</td>\n",
       "      <td>-135577.083002</td>\n",
       "      <td>5.937735e+05</td>\n",
       "      <td>298881.389809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>140768.307971</td>\n",
       "      <td>-138712.863357</td>\n",
       "      <td>5.766936e+05</td>\n",
       "      <td>292310.947302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>132019.875331</td>\n",
       "      <td>-140677.935845</td>\n",
       "      <td>5.792617e+05</td>\n",
       "      <td>302704.943925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>146578.647445</td>\n",
       "      <td>-136988.567920</td>\n",
       "      <td>5.923121e+05</td>\n",
       "      <td>297507.491138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>160188.350900</td>\n",
       "      <td>-130429.266402</td>\n",
       "      <td>6.169305e+05</td>\n",
       "      <td>299659.853107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>183485.087490</td>\n",
       "      <td>-122673.149553</td>\n",
       "      <td>6.462202e+05</td>\n",
       "      <td>300909.493239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>197495.987505</td>\n",
       "      <td>-113802.329606</td>\n",
       "      <td>6.920645e+05</td>\n",
       "      <td>316563.267304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>208241.349284</td>\n",
       "      <td>-104333.864067</td>\n",
       "      <td>7.481941e+05</td>\n",
       "      <td>341867.628105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>436159.518318</td>\n",
       "      <td>-25389.243398</td>\n",
       "      <td>1.284996e+06</td>\n",
       "      <td>558794.970443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>440036.403068</td>\n",
       "      <td>-21408.213982</td>\n",
       "      <td>1.286372e+06</td>\n",
       "      <td>551557.488360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>441067.787352</td>\n",
       "      <td>-17032.050651</td>\n",
       "      <td>1.294618e+06</td>\n",
       "      <td>531128.390114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>436708.350883</td>\n",
       "      <td>-13405.232367</td>\n",
       "      <td>1.307245e+06</td>\n",
       "      <td>510691.928360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>123590.371191</td>\n",
       "      <td>204849.334118</td>\n",
       "      <td>2.889040e+05</td>\n",
       "      <td>90756.290792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>155906.168178</td>\n",
       "      <td>237763.627924</td>\n",
       "      <td>3.387615e+05</td>\n",
       "      <td>78899.493321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>258994.882961</td>\n",
       "      <td>311690.064274</td>\n",
       "      <td>3.999923e+05</td>\n",
       "      <td>56718.916936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>362140.462236</td>\n",
       "      <td>390419.509671</td>\n",
       "      <td>3.822228e+05</td>\n",
       "      <td>2293.768613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>115807.158109</td>\n",
       "      <td>185190.726812</td>\n",
       "      <td>4.557666e+05</td>\n",
       "      <td>127794.767052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>94942.873553</td>\n",
       "      <td>174192.161278</td>\n",
       "      <td>4.306677e+05</td>\n",
       "      <td>149033.239947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>63523.953592</td>\n",
       "      <td>154912.662051</td>\n",
       "      <td>3.658771e+05</td>\n",
       "      <td>148425.392448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>21595.601842</td>\n",
       "      <td>138262.088150</td>\n",
       "      <td>3.138025e+05</td>\n",
       "      <td>151465.102391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>3194.346743</td>\n",
       "      <td>132505.563213</td>\n",
       "      <td>2.849950e+05</td>\n",
       "      <td>143384.549078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3176</th>\n",
       "      <td>-52290.804649</td>\n",
       "      <td>120552.768910</td>\n",
       "      <td>2.438152e+05</td>\n",
       "      <td>142529.780901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3177</th>\n",
       "      <td>-72709.281768</td>\n",
       "      <td>116237.813828</td>\n",
       "      <td>2.122628e+05</td>\n",
       "      <td>134281.737772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>-80203.187044</td>\n",
       "      <td>124809.788858</td>\n",
       "      <td>1.855106e+05</td>\n",
       "      <td>122021.382528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3179</th>\n",
       "      <td>-70631.842211</td>\n",
       "      <td>136279.289793</td>\n",
       "      <td>1.843514e+05</td>\n",
       "      <td>118607.612229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>-29568.251044</td>\n",
       "      <td>158524.151101</td>\n",
       "      <td>2.024507e+05</td>\n",
       "      <td>114641.606674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>41996.002828</td>\n",
       "      <td>198260.639911</td>\n",
       "      <td>2.642735e+05</td>\n",
       "      <td>126150.955565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>-7178.989091</td>\n",
       "      <td>171418.346827</td>\n",
       "      <td>2.216657e+05</td>\n",
       "      <td>111036.765818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>24211.681976</td>\n",
       "      <td>189420.717577</td>\n",
       "      <td>2.549081e+05</td>\n",
       "      <td>117110.978741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>46146.057987</td>\n",
       "      <td>210689.807669</td>\n",
       "      <td>2.904127e+05</td>\n",
       "      <td>119258.521213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>81873.076787</td>\n",
       "      <td>240803.591399</td>\n",
       "      <td>3.312985e+05</td>\n",
       "      <td>117836.190941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>91219.333987</td>\n",
       "      <td>251690.748232</td>\n",
       "      <td>3.458126e+05</td>\n",
       "      <td>111972.159783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>165337.526042</td>\n",
       "      <td>303658.643434</td>\n",
       "      <td>3.850052e+05</td>\n",
       "      <td>99649.848146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>218324.889985</td>\n",
       "      <td>336666.741433</td>\n",
       "      <td>4.107540e+05</td>\n",
       "      <td>93304.413809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>271967.320240</td>\n",
       "      <td>373998.567345</td>\n",
       "      <td>4.475162e+05</td>\n",
       "      <td>62451.415815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>329456.272610</td>\n",
       "      <td>427629.783116</td>\n",
       "      <td>4.908657e+05</td>\n",
       "      <td>-64610.841125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>311306.102774</td>\n",
       "      <td>440209.946002</td>\n",
       "      <td>5.659422e+05</td>\n",
       "      <td>-227679.126659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>312177.529877</td>\n",
       "      <td>467794.227854</td>\n",
       "      <td>6.414794e+05</td>\n",
       "      <td>-447081.013308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>-204226.211193</td>\n",
       "      <td>131802.201044</td>\n",
       "      <td>6.071940e+05</td>\n",
       "      <td>-529683.786262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>-218403.781070</td>\n",
       "      <td>127053.722642</td>\n",
       "      <td>4.881802e+05</td>\n",
       "      <td>-409194.134142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>-180941.377519</td>\n",
       "      <td>136493.872221</td>\n",
       "      <td>3.732068e+05</td>\n",
       "      <td>-229020.857831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>-131748.059677</td>\n",
       "      <td>154168.903457</td>\n",
       "      <td>2.758624e+05</td>\n",
       "      <td>-68742.899245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3197 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0              1             2              3\n",
       "0     540939.044324   74114.486668  1.263286e+06  485274.742942\n",
       "1     536382.454536   68441.372560  1.283827e+06  483969.608486\n",
       "2     520182.714285   56714.405780  1.331607e+06  427112.547630\n",
       "3     486431.761113   48242.362221  1.428792e+06  307522.893686\n",
       "4     440245.130499   34537.029177  1.537833e+06  137166.671000\n",
       "5     398319.292181   20745.263023  1.621320e+06  -31864.918446\n",
       "6     355245.285097    4320.396100  1.629135e+06 -117645.717741\n",
       "7     352410.378531   -5128.032271  1.545080e+06  -40748.896876\n",
       "8     367237.354002  -14333.459813  1.394869e+06  106217.093674\n",
       "9     385502.514965  -22058.060969  1.237396e+06  251204.074143\n",
       "10    375887.620113  -35186.117668  1.103805e+06  362896.105609\n",
       "11    355873.918123  -49310.287777  9.931661e+05  388316.332034\n",
       "12    320070.053228  -66305.355608  9.265297e+05  379025.311114\n",
       "13    294253.966470  -80961.821221  8.465183e+05  355049.076039\n",
       "14    261176.688890  -94335.128250  7.787097e+05  334956.187817\n",
       "15    220939.469442 -107339.238086  7.230176e+05  326678.561463\n",
       "16    187404.753201 -119548.387660  6.675592e+05  312712.572966\n",
       "17    154012.988096 -130805.384930  6.252785e+05  308959.744079\n",
       "18    146434.720910 -135577.083002  5.937735e+05  298881.389809\n",
       "19    140768.307971 -138712.863357  5.766936e+05  292310.947302\n",
       "20    132019.875331 -140677.935845  5.792617e+05  302704.943925\n",
       "21    146578.647445 -136988.567920  5.923121e+05  297507.491138\n",
       "22    160188.350900 -130429.266402  6.169305e+05  299659.853107\n",
       "23    183485.087490 -122673.149553  6.462202e+05  300909.493239\n",
       "24    197495.987505 -113802.329606  6.920645e+05  316563.267304\n",
       "25    208241.349284 -104333.864067  7.481941e+05  341867.628105\n",
       "26    436159.518318  -25389.243398  1.284996e+06  558794.970443\n",
       "27    440036.403068  -21408.213982  1.286372e+06  551557.488360\n",
       "28    441067.787352  -17032.050651  1.294618e+06  531128.390114\n",
       "29    436708.350883  -13405.232367  1.307245e+06  510691.928360\n",
       "...             ...            ...           ...            ...\n",
       "3167  123590.371191  204849.334118  2.889040e+05   90756.290792\n",
       "3168  155906.168178  237763.627924  3.387615e+05   78899.493321\n",
       "3169  258994.882961  311690.064274  3.999923e+05   56718.916936\n",
       "3170  362140.462236  390419.509671  3.822228e+05    2293.768613\n",
       "3171  115807.158109  185190.726812  4.557666e+05  127794.767052\n",
       "3172   94942.873553  174192.161278  4.306677e+05  149033.239947\n",
       "3173   63523.953592  154912.662051  3.658771e+05  148425.392448\n",
       "3174   21595.601842  138262.088150  3.138025e+05  151465.102391\n",
       "3175    3194.346743  132505.563213  2.849950e+05  143384.549078\n",
       "3176  -52290.804649  120552.768910  2.438152e+05  142529.780901\n",
       "3177  -72709.281768  116237.813828  2.122628e+05  134281.737772\n",
       "3178  -80203.187044  124809.788858  1.855106e+05  122021.382528\n",
       "3179  -70631.842211  136279.289793  1.843514e+05  118607.612229\n",
       "3180  -29568.251044  158524.151101  2.024507e+05  114641.606674\n",
       "3181   41996.002828  198260.639911  2.642735e+05  126150.955565\n",
       "3182   -7178.989091  171418.346827  2.216657e+05  111036.765818\n",
       "3183   24211.681976  189420.717577  2.549081e+05  117110.978741\n",
       "3184   46146.057987  210689.807669  2.904127e+05  119258.521213\n",
       "3185   81873.076787  240803.591399  3.312985e+05  117836.190941\n",
       "3186   91219.333987  251690.748232  3.458126e+05  111972.159783\n",
       "3187  165337.526042  303658.643434  3.850052e+05   99649.848146\n",
       "3188  218324.889985  336666.741433  4.107540e+05   93304.413809\n",
       "3189  271967.320240  373998.567345  4.475162e+05   62451.415815\n",
       "3190  329456.272610  427629.783116  4.908657e+05  -64610.841125\n",
       "3191  311306.102774  440209.946002  5.659422e+05 -227679.126659\n",
       "3192  312177.529877  467794.227854  6.414794e+05 -447081.013308\n",
       "3193 -204226.211193  131802.201044  6.071940e+05 -529683.786262\n",
       "3194 -218403.781070  127053.722642  4.881802e+05 -409194.134142\n",
       "3195 -180941.377519  136493.872221  3.732068e+05 -229020.857831\n",
       "3196 -131748.059677  154168.903457  2.758624e+05  -68742.899245\n",
       "\n",
       "[3197 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(ICA1.mixing_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ICA.mixing_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T18:52:10.824538Z",
     "start_time": "2018-02-07T18:52:10.811037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets check the Principal Component Analysis\n"
     ]
    }
   ],
   "source": [
    "print('Lets check the Principal Component Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T19:10:45.708490Z",
     "start_time": "2018-02-07T18:57:24.549034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(copy=True, iterated_power=500, n_components=4, random_state=None,\n",
      "  svd_solver='randomized', tol=0.0025, whiten=True)\n",
      "fitting the  PCA \n",
      "all done ^__^\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "PCA = PCA(n_components= 4, svd_solver='randomized', whiten=True, tol=0.0025, iterated_power=500)\n",
    "print(PCA)\n",
    "print('fitting the  PCA ')\n",
    "PCA.fit(x_train) #y ignored\n",
    "print('all done ^__^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T19:25:50.819184Z",
     "start_time": "2018-02-07T19:11:52.248430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming the PCA data\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "print('transforming the PCA data')\n",
    "PCA.fit_transform(x_train)\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T06:22:26.261036Z",
     "start_time": "2018-02-08T06:22:26.090539Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ICA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-98dcc4de9ccc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mICA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixing_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mICA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mICA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ICA' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "mix = ICA.mixing_\n",
    "mean= ICA.mean_\n",
    "\n",
    "\n",
    "models = [mix, x_train, ICA.fit_transform(x_train), PCA.fit_transform(x_train)]\n",
    "names = ['Observations (mixed signal)',\n",
    "         'True Sources',\n",
    "         'ICA recovered signals',\n",
    "         'PCA recovered signals']\n",
    "colors = ['red', 'steelblue', 'orange']\n",
    "\n",
    "for ii, (model, name) in enumerate(zip(models, names), 1):\n",
    "    plt.subplot(4, 1, ii)\n",
    "    plt.title(name)\n",
    "    plt.legend(models)\n",
    "    for sig, color in zip(model.T, colors):\n",
    "        plt.plot(sig, color=color)\n",
    "\n",
    "\n",
    "# plt.subplots_adjust(0.09, 0.04, 0.94, 0.94, 0.26, 0.46)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('that was fun.. time for the actual analyzing ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T21:13:22.461208Z",
     "start_time": "2018-02-07T21:13:22.153714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3187</th>\n",
       "      <th>3188</th>\n",
       "      <th>3189</th>\n",
       "      <th>3190</th>\n",
       "      <th>3191</th>\n",
       "      <th>3192</th>\n",
       "      <th>3193</th>\n",
       "      <th>3194</th>\n",
       "      <th>3195</th>\n",
       "      <th>3196</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-18.31</td>\n",
       "      <td>4.13</td>\n",
       "      <td>76.75</td>\n",
       "      <td>9.38</td>\n",
       "      <td>-9.81</td>\n",
       "      <td>5.44</td>\n",
       "      <td>-63.56</td>\n",
       "      <td>27.00</td>\n",
       "      <td>-65.00</td>\n",
       "      <td>-7.56</td>\n",
       "      <td>...</td>\n",
       "      <td>57.00</td>\n",
       "      <td>41.69</td>\n",
       "      <td>75.75</td>\n",
       "      <td>99.63</td>\n",
       "      <td>59.88</td>\n",
       "      <td>71.57</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>86.07</td>\n",
       "      <td>171.57</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-34.33</td>\n",
       "      <td>-32.28</td>\n",
       "      <td>-40.90</td>\n",
       "      <td>21.74</td>\n",
       "      <td>4.61</td>\n",
       "      <td>-6.79</td>\n",
       "      <td>5.96</td>\n",
       "      <td>6.77</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-3.37</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.31</td>\n",
       "      <td>-23.54</td>\n",
       "      <td>-31.36</td>\n",
       "      <td>-12.01</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-4.22</td>\n",
       "      <td>7.97</td>\n",
       "      <td>33.43</td>\n",
       "      <td>20.08</td>\n",
       "      <td>52.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.27</td>\n",
       "      <td>-4.88</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>11.62</td>\n",
       "      <td>-1.82</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>2.91</td>\n",
       "      <td>0.83</td>\n",
       "      <td>...</td>\n",
       "      <td>4.26</td>\n",
       "      <td>9.59</td>\n",
       "      <td>11.63</td>\n",
       "      <td>10.33</td>\n",
       "      <td>10.68</td>\n",
       "      <td>9.02</td>\n",
       "      <td>8.87</td>\n",
       "      <td>12.61</td>\n",
       "      <td>7.84</td>\n",
       "      <td>10.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.81</td>\n",
       "      <td>-7.97</td>\n",
       "      <td>-10.10</td>\n",
       "      <td>-7.18</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-5.71</td>\n",
       "      <td>-11.40</td>\n",
       "      <td>-12.06</td>\n",
       "      <td>-8.82</td>\n",
       "      <td>-13.77</td>\n",
       "      <td>...</td>\n",
       "      <td>17.75</td>\n",
       "      <td>29.47</td>\n",
       "      <td>30.04</td>\n",
       "      <td>19.55</td>\n",
       "      <td>24.50</td>\n",
       "      <td>23.20</td>\n",
       "      <td>25.64</td>\n",
       "      <td>24.25</td>\n",
       "      <td>21.12</td>\n",
       "      <td>23.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128.71</td>\n",
       "      <td>82.93</td>\n",
       "      <td>81.93</td>\n",
       "      <td>-14.92</td>\n",
       "      <td>-32.48</td>\n",
       "      <td>-52.90</td>\n",
       "      <td>-68.76</td>\n",
       "      <td>-122.28</td>\n",
       "      <td>-110.59</td>\n",
       "      <td>-126.03</td>\n",
       "      <td>...</td>\n",
       "      <td>-195.64</td>\n",
       "      <td>-136.14</td>\n",
       "      <td>-100.68</td>\n",
       "      <td>-120.93</td>\n",
       "      <td>-144.78</td>\n",
       "      <td>-75.18</td>\n",
       "      <td>-192.45</td>\n",
       "      <td>-186.62</td>\n",
       "      <td>-154.68</td>\n",
       "      <td>-148.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-3.17</td>\n",
       "      <td>-14.06</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-7.83</td>\n",
       "      <td>-6.19</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>-6.66</td>\n",
       "      <td>-6.85</td>\n",
       "      <td>-10.87</td>\n",
       "      <td>-9.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>6.41</td>\n",
       "      <td>4.29</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-4.45</td>\n",
       "      <td>-5.24</td>\n",
       "      <td>-10.08</td>\n",
       "      <td>-1.93</td>\n",
       "      <td>-2.11</td>\n",
       "      <td>-1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>227.72</td>\n",
       "      <td>188.61</td>\n",
       "      <td>210.38</td>\n",
       "      <td>193.76</td>\n",
       "      <td>165.76</td>\n",
       "      <td>174.02</td>\n",
       "      <td>167.70</td>\n",
       "      <td>174.46</td>\n",
       "      <td>144.67</td>\n",
       "      <td>138.38</td>\n",
       "      <td>...</td>\n",
       "      <td>1.59</td>\n",
       "      <td>14.82</td>\n",
       "      <td>-9.27</td>\n",
       "      <td>30.80</td>\n",
       "      <td>17.86</td>\n",
       "      <td>14.79</td>\n",
       "      <td>-20.41</td>\n",
       "      <td>-3.69</td>\n",
       "      <td>7.04</td>\n",
       "      <td>-7.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.69</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.85</td>\n",
       "      <td>4.16</td>\n",
       "      <td>21.55</td>\n",
       "      <td>0.87</td>\n",
       "      <td>8.17</td>\n",
       "      <td>-3.70</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-10.32</td>\n",
       "      <td>...</td>\n",
       "      <td>7.16</td>\n",
       "      <td>7.25</td>\n",
       "      <td>10.85</td>\n",
       "      <td>1.15</td>\n",
       "      <td>7.52</td>\n",
       "      <td>4.80</td>\n",
       "      <td>11.78</td>\n",
       "      <td>16.02</td>\n",
       "      <td>12.61</td>\n",
       "      <td>8.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>167.13</td>\n",
       "      <td>176.70</td>\n",
       "      <td>225.98</td>\n",
       "      <td>215.71</td>\n",
       "      <td>187.91</td>\n",
       "      <td>143.23</td>\n",
       "      <td>115.93</td>\n",
       "      <td>118.84</td>\n",
       "      <td>117.99</td>\n",
       "      <td>122.22</td>\n",
       "      <td>...</td>\n",
       "      <td>54.96</td>\n",
       "      <td>121.89</td>\n",
       "      <td>97.81</td>\n",
       "      <td>86.90</td>\n",
       "      <td>140.41</td>\n",
       "      <td>129.00</td>\n",
       "      <td>-276.35</td>\n",
       "      <td>-175.57</td>\n",
       "      <td>-202.87</td>\n",
       "      <td>-153.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.82</td>\n",
       "      <td>11.78</td>\n",
       "      <td>-7.57</td>\n",
       "      <td>20.52</td>\n",
       "      <td>19.86</td>\n",
       "      <td>17.15</td>\n",
       "      <td>26.63</td>\n",
       "      <td>8.29</td>\n",
       "      <td>10.89</td>\n",
       "      <td>22.06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.53</td>\n",
       "      <td>15.01</td>\n",
       "      <td>3.15</td>\n",
       "      <td>-4.28</td>\n",
       "      <td>27.40</td>\n",
       "      <td>0.46</td>\n",
       "      <td>19.61</td>\n",
       "      <td>16.12</td>\n",
       "      <td>31.12</td>\n",
       "      <td>18.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.41</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>0.58</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.35</td>\n",
       "      <td>-3.78</td>\n",
       "      <td>4.59</td>\n",
       "      <td>...</td>\n",
       "      <td>19.35</td>\n",
       "      <td>19.08</td>\n",
       "      <td>18.09</td>\n",
       "      <td>18.26</td>\n",
       "      <td>18.26</td>\n",
       "      <td>23.42</td>\n",
       "      <td>3.80</td>\n",
       "      <td>-5.43</td>\n",
       "      <td>2.11</td>\n",
       "      <td>-3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-24.93</td>\n",
       "      <td>-19.16</td>\n",
       "      <td>-19.88</td>\n",
       "      <td>-10.51</td>\n",
       "      <td>-3.82</td>\n",
       "      <td>15.17</td>\n",
       "      <td>-12.60</td>\n",
       "      <td>-19.48</td>\n",
       "      <td>-16.36</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>...</td>\n",
       "      <td>10.98</td>\n",
       "      <td>5.02</td>\n",
       "      <td>6.67</td>\n",
       "      <td>4.94</td>\n",
       "      <td>7.97</td>\n",
       "      <td>13.32</td>\n",
       "      <td>-13.26</td>\n",
       "      <td>-13.23</td>\n",
       "      <td>-15.98</td>\n",
       "      <td>-21.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-387.68</td>\n",
       "      <td>-394.12</td>\n",
       "      <td>-402.64</td>\n",
       "      <td>-355.48</td>\n",
       "      <td>-360.40</td>\n",
       "      <td>-341.03</td>\n",
       "      <td>-325.32</td>\n",
       "      <td>-307.01</td>\n",
       "      <td>-316.73</td>\n",
       "      <td>-299.46</td>\n",
       "      <td>...</td>\n",
       "      <td>-228.98</td>\n",
       "      <td>-258.18</td>\n",
       "      <td>-242.92</td>\n",
       "      <td>-257.59</td>\n",
       "      <td>-246.84</td>\n",
       "      <td>-277.98</td>\n",
       "      <td>-163.48</td>\n",
       "      <td>-188.98</td>\n",
       "      <td>-154.53</td>\n",
       "      <td>-174.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29.93</td>\n",
       "      <td>27.00</td>\n",
       "      <td>18.50</td>\n",
       "      <td>18.38</td>\n",
       "      <td>17.88</td>\n",
       "      <td>27.63</td>\n",
       "      <td>13.37</td>\n",
       "      <td>31.75</td>\n",
       "      <td>15.42</td>\n",
       "      <td>13.81</td>\n",
       "      <td>...</td>\n",
       "      <td>11.64</td>\n",
       "      <td>16.60</td>\n",
       "      <td>6.43</td>\n",
       "      <td>28.92</td>\n",
       "      <td>22.21</td>\n",
       "      <td>31.39</td>\n",
       "      <td>-7.79</td>\n",
       "      <td>-12.29</td>\n",
       "      <td>-4.07</td>\n",
       "      <td>-14.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>102.18</td>\n",
       "      <td>93.94</td>\n",
       "      <td>178.05</td>\n",
       "      <td>167.69</td>\n",
       "      <td>162.97</td>\n",
       "      <td>208.90</td>\n",
       "      <td>160.94</td>\n",
       "      <td>188.80</td>\n",
       "      <td>206.18</td>\n",
       "      <td>265.16</td>\n",
       "      <td>...</td>\n",
       "      <td>1186.44</td>\n",
       "      <td>1227.88</td>\n",
       "      <td>1380.36</td>\n",
       "      <td>1391.43</td>\n",
       "      <td>1422.65</td>\n",
       "      <td>1532.46</td>\n",
       "      <td>999.24</td>\n",
       "      <td>1119.93</td>\n",
       "      <td>1187.63</td>\n",
       "      <td>1157.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-31.96</td>\n",
       "      <td>-45.96</td>\n",
       "      <td>-52.25</td>\n",
       "      <td>-27.14</td>\n",
       "      <td>-13.91</td>\n",
       "      <td>-22.81</td>\n",
       "      <td>-9.10</td>\n",
       "      <td>-9.57</td>\n",
       "      <td>-16.14</td>\n",
       "      <td>-10.04</td>\n",
       "      <td>...</td>\n",
       "      <td>15.89</td>\n",
       "      <td>-5.16</td>\n",
       "      <td>16.15</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>27.75</td>\n",
       "      <td>10.85</td>\n",
       "      <td>-37.83</td>\n",
       "      <td>-7.63</td>\n",
       "      <td>11.06</td>\n",
       "      <td>55.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-23.11</td>\n",
       "      <td>-28.12</td>\n",
       "      <td>-31.17</td>\n",
       "      <td>-22.00</td>\n",
       "      <td>-31.20</td>\n",
       "      <td>-38.45</td>\n",
       "      <td>-34.72</td>\n",
       "      <td>-29.72</td>\n",
       "      <td>-34.69</td>\n",
       "      <td>-32.44</td>\n",
       "      <td>...</td>\n",
       "      <td>3.97</td>\n",
       "      <td>10.31</td>\n",
       "      <td>24.56</td>\n",
       "      <td>11.87</td>\n",
       "      <td>9.94</td>\n",
       "      <td>6.87</td>\n",
       "      <td>15.96</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.58</td>\n",
       "      <td>16.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-19.01</td>\n",
       "      <td>12.56</td>\n",
       "      <td>-7.01</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>0.22</td>\n",
       "      <td>6.37</td>\n",
       "      <td>4.95</td>\n",
       "      <td>-7.34</td>\n",
       "      <td>-1.77</td>\n",
       "      <td>-12.56</td>\n",
       "      <td>...</td>\n",
       "      <td>14.12</td>\n",
       "      <td>12.12</td>\n",
       "      <td>11.77</td>\n",
       "      <td>7.99</td>\n",
       "      <td>26.09</td>\n",
       "      <td>14.05</td>\n",
       "      <td>-22.26</td>\n",
       "      <td>-42.51</td>\n",
       "      <td>-39.90</td>\n",
       "      <td>-37.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>99.59</td>\n",
       "      <td>94.59</td>\n",
       "      <td>111.99</td>\n",
       "      <td>116.02</td>\n",
       "      <td>98.83</td>\n",
       "      <td>112.36</td>\n",
       "      <td>116.57</td>\n",
       "      <td>129.82</td>\n",
       "      <td>109.66</td>\n",
       "      <td>107.60</td>\n",
       "      <td>...</td>\n",
       "      <td>20.27</td>\n",
       "      <td>-8.01</td>\n",
       "      <td>-3.05</td>\n",
       "      <td>-11.71</td>\n",
       "      <td>-18.19</td>\n",
       "      <td>-48.82</td>\n",
       "      <td>22.66</td>\n",
       "      <td>36.13</td>\n",
       "      <td>42.78</td>\n",
       "      <td>59.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-636.56</td>\n",
       "      <td>-634.31</td>\n",
       "      <td>-579.28</td>\n",
       "      <td>-491.78</td>\n",
       "      <td>-535.25</td>\n",
       "      <td>-526.91</td>\n",
       "      <td>-434.97</td>\n",
       "      <td>-440.91</td>\n",
       "      <td>-385.38</td>\n",
       "      <td>-330.41</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.00</td>\n",
       "      <td>21.84</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.78</td>\n",
       "      <td>-19.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.62</td>\n",
       "      <td>123.94</td>\n",
       "      <td>163.75</td>\n",
       "      <td>150.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>135.11</td>\n",
       "      <td>119.31</td>\n",
       "      <td>89.51</td>\n",
       "      <td>77.54</td>\n",
       "      <td>83.70</td>\n",
       "      <td>82.43</td>\n",
       "      <td>57.94</td>\n",
       "      <td>52.09</td>\n",
       "      <td>44.02</td>\n",
       "      <td>35.80</td>\n",
       "      <td>...</td>\n",
       "      <td>-215.35</td>\n",
       "      <td>-219.97</td>\n",
       "      <td>-240.87</td>\n",
       "      <td>-256.17</td>\n",
       "      <td>-251.75</td>\n",
       "      <td>-270.57</td>\n",
       "      <td>-206.66</td>\n",
       "      <td>-239.35</td>\n",
       "      <td>-251.63</td>\n",
       "      <td>-261.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-26.27</td>\n",
       "      <td>6.02</td>\n",
       "      <td>-17.62</td>\n",
       "      <td>-7.32</td>\n",
       "      <td>43.75</td>\n",
       "      <td>-49.00</td>\n",
       "      <td>-43.73</td>\n",
       "      <td>-103.93</td>\n",
       "      <td>-73.22</td>\n",
       "      <td>-119.97</td>\n",
       "      <td>...</td>\n",
       "      <td>153.14</td>\n",
       "      <td>72.92</td>\n",
       "      <td>-35.32</td>\n",
       "      <td>-161.79</td>\n",
       "      <td>-258.16</td>\n",
       "      <td>-398.61</td>\n",
       "      <td>-85.39</td>\n",
       "      <td>-61.99</td>\n",
       "      <td>-101.99</td>\n",
       "      <td>-32.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.98</td>\n",
       "      <td>13.98</td>\n",
       "      <td>-3.92</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.71</td>\n",
       "      <td>1.10</td>\n",
       "      <td>13.73</td>\n",
       "      <td>0.90</td>\n",
       "      <td>14.90</td>\n",
       "      <td>-5.26</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.01</td>\n",
       "      <td>-18.16</td>\n",
       "      <td>-42.82</td>\n",
       "      <td>-50.60</td>\n",
       "      <td>-59.30</td>\n",
       "      <td>-70.03</td>\n",
       "      <td>-18.16</td>\n",
       "      <td>-23.42</td>\n",
       "      <td>-12.83</td>\n",
       "      <td>-23.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-21.03</td>\n",
       "      <td>-11.62</td>\n",
       "      <td>-11.33</td>\n",
       "      <td>-7.11</td>\n",
       "      <td>-14.73</td>\n",
       "      <td>-10.03</td>\n",
       "      <td>-12.24</td>\n",
       "      <td>-3.43</td>\n",
       "      <td>-3.95</td>\n",
       "      <td>-6.06</td>\n",
       "      <td>...</td>\n",
       "      <td>8.95</td>\n",
       "      <td>18.08</td>\n",
       "      <td>15.93</td>\n",
       "      <td>21.58</td>\n",
       "      <td>18.99</td>\n",
       "      <td>15.46</td>\n",
       "      <td>-10.78</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>3.88</td>\n",
       "      <td>13.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.74</td>\n",
       "      <td>-10.75</td>\n",
       "      <td>16.21</td>\n",
       "      <td>-30.10</td>\n",
       "      <td>6.43</td>\n",
       "      <td>-3.23</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>25.07</td>\n",
       "      <td>1.88</td>\n",
       "      <td>17.41</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>-3.46</td>\n",
       "      <td>17.55</td>\n",
       "      <td>7.36</td>\n",
       "      <td>-14.54</td>\n",
       "      <td>-14.71</td>\n",
       "      <td>30.02</td>\n",
       "      <td>30.00</td>\n",
       "      <td>12.22</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>69.99</td>\n",
       "      <td>62.46</td>\n",
       "      <td>62.65</td>\n",
       "      <td>36.06</td>\n",
       "      <td>35.93</td>\n",
       "      <td>20.88</td>\n",
       "      <td>22.80</td>\n",
       "      <td>-11.20</td>\n",
       "      <td>9.24</td>\n",
       "      <td>7.66</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.58</td>\n",
       "      <td>-24.83</td>\n",
       "      <td>-15.22</td>\n",
       "      <td>-22.99</td>\n",
       "      <td>-21.95</td>\n",
       "      <td>-8.81</td>\n",
       "      <td>-32.47</td>\n",
       "      <td>-60.32</td>\n",
       "      <td>-22.04</td>\n",
       "      <td>-36.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.27</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>-16.17</td>\n",
       "      <td>-9.63</td>\n",
       "      <td>-14.47</td>\n",
       "      <td>-9.82</td>\n",
       "      <td>-8.01</td>\n",
       "      <td>-7.32</td>\n",
       "      <td>-11.89</td>\n",
       "      <td>-10.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.36</td>\n",
       "      <td>-4.01</td>\n",
       "      <td>-10.49</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.91</td>\n",
       "      <td>9.68</td>\n",
       "      <td>10.87</td>\n",
       "      <td>2.96</td>\n",
       "      <td>-4.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21.75</td>\n",
       "      <td>9.85</td>\n",
       "      <td>9.90</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.01</td>\n",
       "      <td>6.72</td>\n",
       "      <td>7.19</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1.63</td>\n",
       "      <td>5.60</td>\n",
       "      <td>...</td>\n",
       "      <td>15.17</td>\n",
       "      <td>21.37</td>\n",
       "      <td>13.81</td>\n",
       "      <td>12.68</td>\n",
       "      <td>14.75</td>\n",
       "      <td>15.45</td>\n",
       "      <td>1.45</td>\n",
       "      <td>-11.35</td>\n",
       "      <td>1.71</td>\n",
       "      <td>-1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.53</td>\n",
       "      <td>-10.36</td>\n",
       "      <td>32.93</td>\n",
       "      <td>9.11</td>\n",
       "      <td>56.43</td>\n",
       "      <td>44.55</td>\n",
       "      <td>57.28</td>\n",
       "      <td>68.89</td>\n",
       "      <td>90.96</td>\n",
       "      <td>99.97</td>\n",
       "      <td>...</td>\n",
       "      <td>-461.58</td>\n",
       "      <td>-583.55</td>\n",
       "      <td>-732.93</td>\n",
       "      <td>-1081.32</td>\n",
       "      <td>-1234.43</td>\n",
       "      <td>-1540.71</td>\n",
       "      <td>18.43</td>\n",
       "      <td>11.08</td>\n",
       "      <td>30.81</td>\n",
       "      <td>18.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-5.98</td>\n",
       "      <td>9.98</td>\n",
       "      <td>-6.83</td>\n",
       "      <td>2.82</td>\n",
       "      <td>-4.36</td>\n",
       "      <td>-9.29</td>\n",
       "      <td>-10.89</td>\n",
       "      <td>-5.94</td>\n",
       "      <td>-3.93</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.93</td>\n",
       "      <td>8.38</td>\n",
       "      <td>5.15</td>\n",
       "      <td>5.73</td>\n",
       "      <td>9.63</td>\n",
       "      <td>7.49</td>\n",
       "      <td>5.59</td>\n",
       "      <td>26.10</td>\n",
       "      <td>24.72</td>\n",
       "      <td>27.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>6.59</td>\n",
       "      <td>8.80</td>\n",
       "      <td>-3.65</td>\n",
       "      <td>-11.99</td>\n",
       "      <td>-11.20</td>\n",
       "      <td>-26.25</td>\n",
       "      <td>-29.71</td>\n",
       "      <td>-32.48</td>\n",
       "      <td>-38.29</td>\n",
       "      <td>-42.33</td>\n",
       "      <td>...</td>\n",
       "      <td>26.51</td>\n",
       "      <td>26.11</td>\n",
       "      <td>85.98</td>\n",
       "      <td>13.13</td>\n",
       "      <td>4.94</td>\n",
       "      <td>11.95</td>\n",
       "      <td>-14.33</td>\n",
       "      <td>-9.96</td>\n",
       "      <td>4.09</td>\n",
       "      <td>18.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>28.79</td>\n",
       "      <td>27.16</td>\n",
       "      <td>22.20</td>\n",
       "      <td>19.47</td>\n",
       "      <td>14.28</td>\n",
       "      <td>21.57</td>\n",
       "      <td>12.09</td>\n",
       "      <td>15.75</td>\n",
       "      <td>11.14</td>\n",
       "      <td>9.11</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.09</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-6.39</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-9.57</td>\n",
       "      <td>-12.04</td>\n",
       "      <td>-12.82</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>-83.00</td>\n",
       "      <td>-78.50</td>\n",
       "      <td>-83.66</td>\n",
       "      <td>-77.41</td>\n",
       "      <td>-78.65</td>\n",
       "      <td>-75.56</td>\n",
       "      <td>-73.94</td>\n",
       "      <td>-78.95</td>\n",
       "      <td>-78.06</td>\n",
       "      <td>-71.62</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.94</td>\n",
       "      <td>-28.58</td>\n",
       "      <td>-20.89</td>\n",
       "      <td>-41.61</td>\n",
       "      <td>-42.18</td>\n",
       "      <td>-58.89</td>\n",
       "      <td>-65.94</td>\n",
       "      <td>-73.44</td>\n",
       "      <td>-63.98</td>\n",
       "      <td>-64.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>9.80</td>\n",
       "      <td>21.49</td>\n",
       "      <td>16.65</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.95</td>\n",
       "      <td>13.54</td>\n",
       "      <td>10.76</td>\n",
       "      <td>12.53</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.81</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.65</td>\n",
       "      <td>-18.97</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>-4.41</td>\n",
       "      <td>15.28</td>\n",
       "      <td>-23.37</td>\n",
       "      <td>-25.55</td>\n",
       "      <td>-29.97</td>\n",
       "      <td>-27.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>89.83</td>\n",
       "      <td>79.95</td>\n",
       "      <td>81.44</td>\n",
       "      <td>81.62</td>\n",
       "      <td>79.05</td>\n",
       "      <td>59.33</td>\n",
       "      <td>70.81</td>\n",
       "      <td>77.19</td>\n",
       "      <td>58.30</td>\n",
       "      <td>55.70</td>\n",
       "      <td>...</td>\n",
       "      <td>13.48</td>\n",
       "      <td>20.34</td>\n",
       "      <td>39.27</td>\n",
       "      <td>52.87</td>\n",
       "      <td>64.98</td>\n",
       "      <td>85.77</td>\n",
       "      <td>13.50</td>\n",
       "      <td>10.09</td>\n",
       "      <td>18.49</td>\n",
       "      <td>20.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>159.78</td>\n",
       "      <td>160.60</td>\n",
       "      <td>186.23</td>\n",
       "      <td>179.39</td>\n",
       "      <td>141.31</td>\n",
       "      <td>107.46</td>\n",
       "      <td>131.99</td>\n",
       "      <td>118.75</td>\n",
       "      <td>96.94</td>\n",
       "      <td>70.59</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.46</td>\n",
       "      <td>-18.57</td>\n",
       "      <td>-38.74</td>\n",
       "      <td>-66.59</td>\n",
       "      <td>-90.64</td>\n",
       "      <td>-82.07</td>\n",
       "      <td>-22.15</td>\n",
       "      <td>-28.22</td>\n",
       "      <td>-74.97</td>\n",
       "      <td>-59.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>11.50</td>\n",
       "      <td>8.02</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>7.03</td>\n",
       "      <td>13.37</td>\n",
       "      <td>7.54</td>\n",
       "      <td>6.64</td>\n",
       "      <td>5.31</td>\n",
       "      <td>1.19</td>\n",
       "      <td>-3.34</td>\n",
       "      <td>...</td>\n",
       "      <td>2.13</td>\n",
       "      <td>-3.01</td>\n",
       "      <td>14.45</td>\n",
       "      <td>23.84</td>\n",
       "      <td>14.73</td>\n",
       "      <td>28.74</td>\n",
       "      <td>5.11</td>\n",
       "      <td>2.51</td>\n",
       "      <td>-7.15</td>\n",
       "      <td>-3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>-29.79</td>\n",
       "      <td>-25.91</td>\n",
       "      <td>-25.00</td>\n",
       "      <td>-25.09</td>\n",
       "      <td>-15.33</td>\n",
       "      <td>-19.65</td>\n",
       "      <td>-10.93</td>\n",
       "      <td>-11.99</td>\n",
       "      <td>3.32</td>\n",
       "      <td>-9.25</td>\n",
       "      <td>...</td>\n",
       "      <td>9.29</td>\n",
       "      <td>14.36</td>\n",
       "      <td>8.70</td>\n",
       "      <td>9.04</td>\n",
       "      <td>19.27</td>\n",
       "      <td>13.97</td>\n",
       "      <td>-9.77</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.90</td>\n",
       "      <td>5.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>-188.62</td>\n",
       "      <td>-214.18</td>\n",
       "      <td>-233.90</td>\n",
       "      <td>-282.53</td>\n",
       "      <td>-335.81</td>\n",
       "      <td>-367.81</td>\n",
       "      <td>-405.31</td>\n",
       "      <td>-396.21</td>\n",
       "      <td>-396.28</td>\n",
       "      <td>-370.56</td>\n",
       "      <td>...</td>\n",
       "      <td>8.85</td>\n",
       "      <td>-43.12</td>\n",
       "      <td>-36.53</td>\n",
       "      <td>-6.43</td>\n",
       "      <td>-10.78</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-170.18</td>\n",
       "      <td>-93.96</td>\n",
       "      <td>-112.74</td>\n",
       "      <td>-100.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>4.67</td>\n",
       "      <td>-1.77</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>-3.44</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-6.07</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-4.04</td>\n",
       "      <td>-4.41</td>\n",
       "      <td>8.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-5.47</td>\n",
       "      <td>-15.90</td>\n",
       "      <td>-4.93</td>\n",
       "      <td>-9.49</td>\n",
       "      <td>-13.11</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>1.85</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>15.62</td>\n",
       "      <td>-25.58</td>\n",
       "      <td>-30.91</td>\n",
       "      <td>-41.41</td>\n",
       "      <td>-8.16</td>\n",
       "      <td>-23.55</td>\n",
       "      <td>-3.63</td>\n",
       "      <td>-55.25</td>\n",
       "      <td>-56.61</td>\n",
       "      <td>-62.33</td>\n",
       "      <td>...</td>\n",
       "      <td>26.31</td>\n",
       "      <td>-3.55</td>\n",
       "      <td>0.44</td>\n",
       "      <td>6.80</td>\n",
       "      <td>17.86</td>\n",
       "      <td>33.58</td>\n",
       "      <td>-15.10</td>\n",
       "      <td>-111.61</td>\n",
       "      <td>-147.31</td>\n",
       "      <td>-123.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>-20.35</td>\n",
       "      <td>-26.38</td>\n",
       "      <td>-21.92</td>\n",
       "      <td>15.82</td>\n",
       "      <td>-17.67</td>\n",
       "      <td>-11.34</td>\n",
       "      <td>-9.30</td>\n",
       "      <td>-6.23</td>\n",
       "      <td>-13.70</td>\n",
       "      <td>-18.47</td>\n",
       "      <td>...</td>\n",
       "      <td>8.76</td>\n",
       "      <td>7.67</td>\n",
       "      <td>-2.72</td>\n",
       "      <td>0.06</td>\n",
       "      <td>20.63</td>\n",
       "      <td>2.67</td>\n",
       "      <td>-17.93</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-16.48</td>\n",
       "      <td>-7.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>-2.30</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>-13.75</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-5.13</td>\n",
       "      <td>1.63</td>\n",
       "      <td>-5.90</td>\n",
       "      <td>-8.76</td>\n",
       "      <td>-7.46</td>\n",
       "      <td>-7.95</td>\n",
       "      <td>...</td>\n",
       "      <td>1.47</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>0.18</td>\n",
       "      <td>6.95</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.31</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>1.89</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>-8.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>3.15</td>\n",
       "      <td>1.68</td>\n",
       "      <td>-4.79</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-10.59</td>\n",
       "      <td>-6.10</td>\n",
       "      <td>-6.29</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>-4.48</td>\n",
       "      <td>-2.37</td>\n",
       "      <td>...</td>\n",
       "      <td>4.79</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>-3.67</td>\n",
       "      <td>3.42</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>-2.90</td>\n",
       "      <td>-40.80</td>\n",
       "      <td>-35.80</td>\n",
       "      <td>-31.13</td>\n",
       "      <td>-27.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>462.33</td>\n",
       "      <td>383.22</td>\n",
       "      <td>342.29</td>\n",
       "      <td>257.18</td>\n",
       "      <td>225.20</td>\n",
       "      <td>193.92</td>\n",
       "      <td>151.09</td>\n",
       "      <td>163.88</td>\n",
       "      <td>124.29</td>\n",
       "      <td>65.51</td>\n",
       "      <td>...</td>\n",
       "      <td>191.67</td>\n",
       "      <td>108.11</td>\n",
       "      <td>117.49</td>\n",
       "      <td>39.64</td>\n",
       "      <td>63.49</td>\n",
       "      <td>11.90</td>\n",
       "      <td>-453.22</td>\n",
       "      <td>-443.06</td>\n",
       "      <td>-414.82</td>\n",
       "      <td>-294.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>-6.91</td>\n",
       "      <td>-14.21</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-13.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-3.85</td>\n",
       "      <td>-3.81</td>\n",
       "      <td>9.13</td>\n",
       "      <td>8.14</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>29.31</td>\n",
       "      <td>35.99</td>\n",
       "      <td>15.19</td>\n",
       "      <td>22.07</td>\n",
       "      <td>7.40</td>\n",
       "      <td>-10.60</td>\n",
       "      <td>3.72</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>15.62</td>\n",
       "      <td>-6.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>122.63</td>\n",
       "      <td>137.56</td>\n",
       "      <td>109.06</td>\n",
       "      <td>135.08</td>\n",
       "      <td>92.80</td>\n",
       "      <td>165.45</td>\n",
       "      <td>83.80</td>\n",
       "      <td>50.57</td>\n",
       "      <td>12.06</td>\n",
       "      <td>8.13</td>\n",
       "      <td>...</td>\n",
       "      <td>-108.38</td>\n",
       "      <td>-144.60</td>\n",
       "      <td>-140.03</td>\n",
       "      <td>-170.23</td>\n",
       "      <td>-191.24</td>\n",
       "      <td>-184.60</td>\n",
       "      <td>-137.77</td>\n",
       "      <td>-133.70</td>\n",
       "      <td>-192.78</td>\n",
       "      <td>-161.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>-1090.87</td>\n",
       "      <td>-1168.93</td>\n",
       "      <td>-1154.31</td>\n",
       "      <td>-991.00</td>\n",
       "      <td>-1016.12</td>\n",
       "      <td>-930.12</td>\n",
       "      <td>-688.93</td>\n",
       "      <td>-747.12</td>\n",
       "      <td>-594.12</td>\n",
       "      <td>-586.43</td>\n",
       "      <td>...</td>\n",
       "      <td>-440.93</td>\n",
       "      <td>-327.19</td>\n",
       "      <td>-371.69</td>\n",
       "      <td>-289.93</td>\n",
       "      <td>-497.43</td>\n",
       "      <td>-488.62</td>\n",
       "      <td>-944.75</td>\n",
       "      <td>-849.37</td>\n",
       "      <td>-909.75</td>\n",
       "      <td>-904.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>2.13</td>\n",
       "      <td>1.87</td>\n",
       "      <td>-4.16</td>\n",
       "      <td>0.87</td>\n",
       "      <td>-3.38</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-3.25</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>-2.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.63</td>\n",
       "      <td>-2.64</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>-6.52</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-4.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>5.74</td>\n",
       "      <td>2.19</td>\n",
       "      <td>8.66</td>\n",
       "      <td>5.31</td>\n",
       "      <td>7.40</td>\n",
       "      <td>2.92</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1.27</td>\n",
       "      <td>6.12</td>\n",
       "      <td>1.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>10.97</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>2.55</td>\n",
       "      <td>6.64</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-6.64</td>\n",
       "      <td>-7.79</td>\n",
       "      <td>-3.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>125.57</td>\n",
       "      <td>78.69</td>\n",
       "      <td>98.29</td>\n",
       "      <td>91.16</td>\n",
       "      <td>78.42</td>\n",
       "      <td>45.82</td>\n",
       "      <td>61.69</td>\n",
       "      <td>22.73</td>\n",
       "      <td>39.09</td>\n",
       "      <td>10.92</td>\n",
       "      <td>...</td>\n",
       "      <td>32.35</td>\n",
       "      <td>63.23</td>\n",
       "      <td>57.98</td>\n",
       "      <td>90.43</td>\n",
       "      <td>115.12</td>\n",
       "      <td>210.09</td>\n",
       "      <td>3.80</td>\n",
       "      <td>16.33</td>\n",
       "      <td>27.35</td>\n",
       "      <td>21.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>7.45</td>\n",
       "      <td>10.02</td>\n",
       "      <td>6.87</td>\n",
       "      <td>-2.82</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-4.30</td>\n",
       "      <td>-7.01</td>\n",
       "      <td>-6.97</td>\n",
       "      <td>-2.54</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.25</td>\n",
       "      <td>-8.56</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-4.29</td>\n",
       "      <td>-6.60</td>\n",
       "      <td>8.75</td>\n",
       "      <td>-10.69</td>\n",
       "      <td>-9.54</td>\n",
       "      <td>-2.48</td>\n",
       "      <td>-8.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>475.61</td>\n",
       "      <td>395.50</td>\n",
       "      <td>423.61</td>\n",
       "      <td>376.36</td>\n",
       "      <td>338.94</td>\n",
       "      <td>321.26</td>\n",
       "      <td>326.34</td>\n",
       "      <td>342.84</td>\n",
       "      <td>251.23</td>\n",
       "      <td>217.32</td>\n",
       "      <td>...</td>\n",
       "      <td>543.25</td>\n",
       "      <td>453.87</td>\n",
       "      <td>344.35</td>\n",
       "      <td>266.16</td>\n",
       "      <td>242.18</td>\n",
       "      <td>163.02</td>\n",
       "      <td>86.29</td>\n",
       "      <td>13.06</td>\n",
       "      <td>161.22</td>\n",
       "      <td>213.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>-46.63</td>\n",
       "      <td>-55.39</td>\n",
       "      <td>-64.88</td>\n",
       "      <td>-88.75</td>\n",
       "      <td>-75.40</td>\n",
       "      <td>-64.06</td>\n",
       "      <td>-66.37</td>\n",
       "      <td>-41.95</td>\n",
       "      <td>-68.07</td>\n",
       "      <td>-76.27</td>\n",
       "      <td>...</td>\n",
       "      <td>29.64</td>\n",
       "      <td>6.90</td>\n",
       "      <td>32.94</td>\n",
       "      <td>56.63</td>\n",
       "      <td>28.71</td>\n",
       "      <td>28.82</td>\n",
       "      <td>-20.12</td>\n",
       "      <td>-14.41</td>\n",
       "      <td>-43.35</td>\n",
       "      <td>-30.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>299.41</td>\n",
       "      <td>302.77</td>\n",
       "      <td>278.68</td>\n",
       "      <td>263.48</td>\n",
       "      <td>236.89</td>\n",
       "      <td>186.93</td>\n",
       "      <td>145.45</td>\n",
       "      <td>151.20</td>\n",
       "      <td>123.38</td>\n",
       "      <td>92.51</td>\n",
       "      <td>...</td>\n",
       "      <td>-126.36</td>\n",
       "      <td>-133.82</td>\n",
       "      <td>-134.02</td>\n",
       "      <td>-98.76</td>\n",
       "      <td>-106.60</td>\n",
       "      <td>-74.95</td>\n",
       "      <td>-46.29</td>\n",
       "      <td>-3.08</td>\n",
       "      <td>-28.43</td>\n",
       "      <td>-48.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>-91.91</td>\n",
       "      <td>-92.97</td>\n",
       "      <td>-78.76</td>\n",
       "      <td>-97.33</td>\n",
       "      <td>-68.00</td>\n",
       "      <td>-68.24</td>\n",
       "      <td>-75.48</td>\n",
       "      <td>-49.25</td>\n",
       "      <td>-30.92</td>\n",
       "      <td>-11.88</td>\n",
       "      <td>...</td>\n",
       "      <td>139.95</td>\n",
       "      <td>147.26</td>\n",
       "      <td>156.95</td>\n",
       "      <td>155.64</td>\n",
       "      <td>156.36</td>\n",
       "      <td>151.75</td>\n",
       "      <td>-24.45</td>\n",
       "      <td>-17.00</td>\n",
       "      <td>3.23</td>\n",
       "      <td>19.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>989.75</td>\n",
       "      <td>891.01</td>\n",
       "      <td>908.53</td>\n",
       "      <td>851.83</td>\n",
       "      <td>755.11</td>\n",
       "      <td>615.78</td>\n",
       "      <td>595.77</td>\n",
       "      <td>458.87</td>\n",
       "      <td>492.84</td>\n",
       "      <td>384.34</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.50</td>\n",
       "      <td>-4.84</td>\n",
       "      <td>-76.30</td>\n",
       "      <td>-37.84</td>\n",
       "      <td>-153.83</td>\n",
       "      <td>-136.16</td>\n",
       "      <td>38.03</td>\n",
       "      <td>100.28</td>\n",
       "      <td>-45.64</td>\n",
       "      <td>35.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>273.39</td>\n",
       "      <td>278.00</td>\n",
       "      <td>261.73</td>\n",
       "      <td>236.99</td>\n",
       "      <td>280.73</td>\n",
       "      <td>264.90</td>\n",
       "      <td>252.92</td>\n",
       "      <td>254.88</td>\n",
       "      <td>237.60</td>\n",
       "      <td>238.51</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.82</td>\n",
       "      <td>-53.89</td>\n",
       "      <td>-48.71</td>\n",
       "      <td>30.99</td>\n",
       "      <td>15.96</td>\n",
       "      <td>-3.47</td>\n",
       "      <td>65.73</td>\n",
       "      <td>88.42</td>\n",
       "      <td>79.07</td>\n",
       "      <td>79.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>3.82</td>\n",
       "      <td>2.09</td>\n",
       "      <td>-3.29</td>\n",
       "      <td>-2.88</td>\n",
       "      <td>1.66</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>3.85</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>3.28</td>\n",
       "      <td>6.29</td>\n",
       "      <td>...</td>\n",
       "      <td>10.86</td>\n",
       "      <td>-3.23</td>\n",
       "      <td>-5.10</td>\n",
       "      <td>-4.61</td>\n",
       "      <td>-9.82</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>-4.65</td>\n",
       "      <td>-14.55</td>\n",
       "      <td>-6.41</td>\n",
       "      <td>-2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>323.28</td>\n",
       "      <td>306.36</td>\n",
       "      <td>293.16</td>\n",
       "      <td>287.67</td>\n",
       "      <td>249.89</td>\n",
       "      <td>218.30</td>\n",
       "      <td>188.86</td>\n",
       "      <td>178.93</td>\n",
       "      <td>118.93</td>\n",
       "      <td>130.68</td>\n",
       "      <td>...</td>\n",
       "      <td>71.19</td>\n",
       "      <td>0.97</td>\n",
       "      <td>55.20</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>-5.50</td>\n",
       "      <td>-25.33</td>\n",
       "      <td>-41.31</td>\n",
       "      <td>-16.72</td>\n",
       "      <td>-14.09</td>\n",
       "      <td>27.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2       3        4       5       6       7     \\\n",
       "0      -18.31     4.13    76.75    9.38    -9.81    5.44  -63.56   27.00   \n",
       "1      -34.33   -32.28   -40.90   21.74     4.61   -6.79    5.96    6.77   \n",
       "2       -0.27    -4.88    -0.23   -0.66    -2.30   11.62   -1.82   -0.39   \n",
       "3       -7.81    -7.97   -10.10   -7.18    -6.37   -5.71  -11.40  -12.06   \n",
       "4      128.71    82.93    81.93  -14.92   -32.48  -52.90  -68.76 -122.28   \n",
       "5       -3.17   -14.06    -0.86   -7.83    -6.19   -4.86   -6.66   -6.85   \n",
       "6      227.72   188.61   210.38  193.76   165.76  174.02  167.70  174.46   \n",
       "7        7.69     0.24     2.85    4.16    21.55    0.87    8.17   -3.70   \n",
       "8      167.13   176.70   225.98  215.71   187.91  143.23  115.93  118.84   \n",
       "9       19.82    11.78    -7.57   20.52    19.86   17.15   26.63    8.29   \n",
       "10       3.41    -0.35    -6.18   -2.56     0.58   -0.25    1.32    1.35   \n",
       "11     -24.93   -19.16   -19.88  -10.51    -3.82   15.17  -12.60  -19.48   \n",
       "12    -387.68  -394.12  -402.64 -355.48  -360.40 -341.03 -325.32 -307.01   \n",
       "13      29.93    27.00    18.50   18.38    17.88   27.63   13.37   31.75   \n",
       "14     102.18    93.94   178.05  167.69   162.97  208.90  160.94  188.80   \n",
       "15     -31.96   -45.96   -52.25  -27.14   -13.91  -22.81   -9.10   -9.57   \n",
       "16     -23.11   -28.12   -31.17  -22.00   -31.20  -38.45  -34.72  -29.72   \n",
       "17     -19.01    12.56    -7.01   -3.14     0.22    6.37    4.95   -7.34   \n",
       "18      99.59    94.59   111.99  116.02    98.83  112.36  116.57  129.82   \n",
       "19    -636.56  -634.31  -579.28 -491.78  -535.25 -526.91 -434.97 -440.91   \n",
       "20     135.11   119.31    89.51   77.54    83.70   82.43   57.94   52.09   \n",
       "21     -26.27     6.02   -17.62   -7.32    43.75  -49.00  -43.73 -103.93   \n",
       "22       9.98    13.98    -3.92    3.77     8.71    1.10   13.73    0.90   \n",
       "23     -21.03   -11.62   -11.33   -7.11   -14.73  -10.03  -12.24   -3.43   \n",
       "24       6.74   -10.75    16.21  -30.10     6.43   -3.23   -2.14   25.07   \n",
       "25      69.99    62.46    62.65   36.06    35.93   20.88   22.80  -11.20   \n",
       "26       5.27    -4.10   -16.17   -9.63   -14.47   -9.82   -8.01   -7.32   \n",
       "27      21.75     9.85     9.90    5.67     7.01    6.72    7.19    7.90   \n",
       "28      10.53   -10.36    32.93    9.11    56.43   44.55   57.28   68.89   \n",
       "29      -5.98     9.98    -6.83    2.82    -4.36   -9.29  -10.89   -5.94   \n",
       "...       ...      ...      ...     ...      ...     ...     ...     ...   \n",
       "2970     6.59     8.80    -3.65  -11.99   -11.20  -26.25  -29.71  -32.48   \n",
       "2971    28.79    27.16    22.20   19.47    14.28   21.57   12.09   15.75   \n",
       "2972   -83.00   -78.50   -83.66  -77.41   -78.65  -75.56  -73.94  -78.95   \n",
       "2973     9.80    21.49    16.65   13.00    13.95   13.54   10.76   12.53   \n",
       "2974    89.83    79.95    81.44   81.62    79.05   59.33   70.81   77.19   \n",
       "2975   159.78   160.60   186.23  179.39   141.31  107.46  131.99  118.75   \n",
       "2976    11.50     8.02    -0.59    7.03    13.37    7.54    6.64    5.31   \n",
       "2977   -29.79   -25.91   -25.00  -25.09   -15.33  -19.65  -10.93  -11.99   \n",
       "2978  -188.62  -214.18  -233.90 -282.53  -335.81 -367.81 -405.31 -396.21   \n",
       "2979     4.67    -1.77    -2.53   -3.44    -0.94   -6.07   -1.03   -4.04   \n",
       "2980    15.62   -25.58   -30.91  -41.41    -8.16  -23.55   -3.63  -55.25   \n",
       "2981   -20.35   -26.38   -21.92   15.82   -17.67  -11.34   -9.30   -6.23   \n",
       "2982    -2.30   -11.70   -13.75   -6.37    -5.13    1.63   -5.90   -8.76   \n",
       "2983     3.15     1.68    -4.79   -0.52   -10.59   -6.10   -6.29   -2.45   \n",
       "2984   462.33   383.22   342.29  257.18   225.20  193.92  151.09  163.88   \n",
       "2985    -6.91   -14.21     0.10  -13.02     0.17   -3.85   -3.81    9.13   \n",
       "2986   122.63   137.56   109.06  135.08    92.80  165.45   83.80   50.57   \n",
       "2987 -1090.87 -1168.93 -1154.31 -991.00 -1016.12 -930.12 -688.93 -747.12   \n",
       "2988     2.13     1.87    -4.16    0.87    -3.38    0.21    0.32   -3.25   \n",
       "2989     5.74     2.19     8.66    5.31     7.40    2.92    7.50    1.27   \n",
       "2990   125.57    78.69    98.29   91.16    78.42   45.82   61.69   22.73   \n",
       "2991     7.45    10.02     6.87   -2.82    -1.56   -4.30   -7.01   -6.97   \n",
       "2992   475.61   395.50   423.61  376.36   338.94  321.26  326.34  342.84   \n",
       "2993   -46.63   -55.39   -64.88  -88.75   -75.40  -64.06  -66.37  -41.95   \n",
       "2994   299.41   302.77   278.68  263.48   236.89  186.93  145.45  151.20   \n",
       "2995   -91.91   -92.97   -78.76  -97.33   -68.00  -68.24  -75.48  -49.25   \n",
       "2996   989.75   891.01   908.53  851.83   755.11  615.78  595.77  458.87   \n",
       "2997   273.39   278.00   261.73  236.99   280.73  264.90  252.92  254.88   \n",
       "2998     3.82     2.09    -3.29   -2.88     1.66   -0.75    3.85   -0.03   \n",
       "2999   323.28   306.36   293.16  287.67   249.89  218.30  188.86  178.93   \n",
       "\n",
       "        8       9      ...        3187     3188     3189     3190     3191  \\\n",
       "0     -65.00   -7.56   ...       57.00    41.69    75.75    99.63    59.88   \n",
       "1      -0.68   -3.37   ...       -7.31   -23.54   -31.36   -12.01    -0.92   \n",
       "2       2.91    0.83   ...        4.26     9.59    11.63    10.33    10.68   \n",
       "3      -8.82  -13.77   ...       17.75    29.47    30.04    19.55    24.50   \n",
       "4    -110.59 -126.03   ...     -195.64  -136.14  -100.68  -120.93  -144.78   \n",
       "5     -10.87   -9.92   ...       -0.64     6.41     4.29    -3.75    -4.45   \n",
       "6     144.67  138.38   ...        1.59    14.82    -9.27    30.80    17.86   \n",
       "7      -0.27  -10.32   ...        7.16     7.25    10.85     1.15     7.52   \n",
       "8     117.99  122.22   ...       54.96   121.89    97.81    86.90   140.41   \n",
       "9      10.89   22.06   ...        3.53    15.01     3.15    -4.28    27.40   \n",
       "10     -3.78    4.59   ...       19.35    19.08    18.09    18.26    18.26   \n",
       "11    -16.36   -9.28   ...       10.98     5.02     6.67     4.94     7.97   \n",
       "12   -316.73 -299.46   ...     -228.98  -258.18  -242.92  -257.59  -246.84   \n",
       "13     15.42   13.81   ...       11.64    16.60     6.43    28.92    22.21   \n",
       "14    206.18  265.16   ...     1186.44  1227.88  1380.36  1391.43  1422.65   \n",
       "15    -16.14  -10.04   ...       15.89    -5.16    16.15    -0.54    27.75   \n",
       "16    -34.69  -32.44   ...        3.97    10.31    24.56    11.87     9.94   \n",
       "17     -1.77  -12.56   ...       14.12    12.12    11.77     7.99    26.09   \n",
       "18    109.66  107.60   ...       20.27    -8.01    -3.05   -11.71   -18.19   \n",
       "19   -385.38 -330.41   ...      -16.00    21.84     3.62     4.78   -19.75   \n",
       "20     44.02   35.80   ...     -215.35  -219.97  -240.87  -256.17  -251.75   \n",
       "21    -73.22 -119.97   ...      153.14    72.92   -35.32  -161.79  -258.16   \n",
       "22     14.90   -5.26   ...      -42.01   -18.16   -42.82   -50.60   -59.30   \n",
       "23     -3.95   -6.06   ...        8.95    18.08    15.93    21.58    18.99   \n",
       "24      1.88   17.41   ...       -0.81    -3.46    17.55     7.36   -14.54   \n",
       "25      9.24    7.66   ...      -16.58   -24.83   -15.22   -22.99   -21.95   \n",
       "26    -11.89  -10.92   ...       -7.36    -4.01   -10.49     1.08     1.03   \n",
       "27      1.63    5.60   ...       15.17    21.37    13.81    12.68    14.75   \n",
       "28     90.96   99.97   ...     -461.58  -583.55  -732.93 -1081.32 -1234.43   \n",
       "29     -3.93   -1.51   ...       -5.93     8.38     5.15     5.73     9.63   \n",
       "...      ...     ...   ...         ...      ...      ...      ...      ...   \n",
       "2970  -38.29  -42.33   ...       26.51    26.11    85.98    13.13     4.94   \n",
       "2971   11.14    9.11   ...       -5.09     3.08     3.16     0.05    -6.39   \n",
       "2972  -78.06  -71.62   ...      -30.94   -28.58   -20.89   -41.61   -42.18   \n",
       "2973    4.32    1.81   ...      -16.65   -18.97    -2.78    -1.50    -4.41   \n",
       "2974   58.30   55.70   ...       13.48    20.34    39.27    52.87    64.98   \n",
       "2975   96.94   70.59   ...      -12.46   -18.57   -38.74   -66.59   -90.64   \n",
       "2976    1.19   -3.34   ...        2.13    -3.01    14.45    23.84    14.73   \n",
       "2977    3.32   -9.25   ...        9.29    14.36     8.70     9.04    19.27   \n",
       "2978 -396.28 -370.56   ...        8.85   -43.12   -36.53    -6.43   -10.78   \n",
       "2979   -4.41    8.83   ...        0.48    -5.47   -15.90    -4.93    -9.49   \n",
       "2980  -56.61  -62.33   ...       26.31    -3.55     0.44     6.80    17.86   \n",
       "2981  -13.70  -18.47   ...        8.76     7.67    -2.72     0.06    20.63   \n",
       "2982   -7.46   -7.95   ...        1.47    -1.57     0.18     6.95     1.83   \n",
       "2983   -4.48   -2.37   ...        4.79    -1.80    -3.67     3.42    -1.91   \n",
       "2984  124.29   65.51   ...      191.67   108.11   117.49    39.64    63.49   \n",
       "2985    8.14   -0.18   ...       29.31    35.99    15.19    22.07     7.40   \n",
       "2986   12.06    8.13   ...     -108.38  -144.60  -140.03  -170.23  -191.24   \n",
       "2987 -594.12 -586.43   ...     -440.93  -327.19  -371.69  -289.93  -497.43   \n",
       "2988   -4.00   -2.68   ...        0.97     1.95     1.57     1.28     2.63   \n",
       "2989    6.12    1.90   ...        0.47    -1.20    10.97    -0.01     2.55   \n",
       "2990   39.09   10.92   ...       32.35    63.23    57.98    90.43   115.12   \n",
       "2991   -2.54   -0.51   ...       -5.25    -8.56     0.53    -4.29    -6.60   \n",
       "2992  251.23  217.32   ...      543.25   453.87   344.35   266.16   242.18   \n",
       "2993  -68.07  -76.27   ...       29.64     6.90    32.94    56.63    28.71   \n",
       "2994  123.38   92.51   ...     -126.36  -133.82  -134.02   -98.76  -106.60   \n",
       "2995  -30.92  -11.88   ...      139.95   147.26   156.95   155.64   156.36   \n",
       "2996  492.84  384.34   ...      -26.50    -4.84   -76.30   -37.84  -153.83   \n",
       "2997  237.60  238.51   ...      -26.82   -53.89   -48.71    30.99    15.96   \n",
       "2998    3.28    6.29   ...       10.86    -3.23    -5.10    -4.61    -9.82   \n",
       "2999  118.93  130.68   ...       71.19     0.97    55.20    -1.63    -5.50   \n",
       "\n",
       "         3192    3193     3194     3195     3196  \n",
       "0       71.57   -0.69    86.07   171.57    75.00  \n",
       "1       -4.22    7.97    33.43    20.08    52.63  \n",
       "2        9.02    8.87    12.61     7.84    10.18  \n",
       "3       23.20   25.64    24.25    21.12    23.55  \n",
       "4      -75.18 -192.45  -186.62  -154.68  -148.03  \n",
       "5       -5.24  -10.08    -1.93    -2.11    -1.14  \n",
       "6       14.79  -20.41    -3.69     7.04    -7.66  \n",
       "7        4.80   11.78    16.02    12.61     8.17  \n",
       "8      129.00 -276.35  -175.57  -202.87  -153.03  \n",
       "9        0.46   19.61    16.12    31.12    18.93  \n",
       "10      23.42    3.80    -5.43     2.11    -3.42  \n",
       "11      13.32  -13.26   -13.23   -15.98   -21.76  \n",
       "12    -277.98 -163.48  -188.98  -154.53  -174.40  \n",
       "13      31.39   -7.79   -12.29    -4.07   -14.55  \n",
       "14    1532.46  999.24  1119.93  1187.63  1157.49  \n",
       "15      10.85  -37.83    -7.63    11.06    55.64  \n",
       "16       6.87   15.96     0.36     8.58    16.59  \n",
       "17      14.05  -22.26   -42.51   -39.90   -37.20  \n",
       "18     -48.82   22.66    36.13    42.78    59.93  \n",
       "19       0.00   62.62   123.94   163.75   150.44  \n",
       "20    -270.57 -206.66  -239.35  -251.63  -261.67  \n",
       "21    -398.61  -85.39   -61.99  -101.99   -32.82  \n",
       "22     -70.03  -18.16   -23.42   -12.83   -23.95  \n",
       "23      15.46  -10.78    -0.35     3.88    13.30  \n",
       "24     -14.71   30.02    30.00    12.22     3.93  \n",
       "25      -8.81  -32.47   -60.32   -22.04   -36.35  \n",
       "26       1.91    9.68    10.87     2.96    -4.87  \n",
       "27      15.45    1.45   -11.35     1.71    -1.87  \n",
       "28   -1540.71   18.43    11.08    30.81    18.62  \n",
       "29       7.49    5.59    26.10    24.72    27.08  \n",
       "...       ...     ...      ...      ...      ...  \n",
       "2970    11.95  -14.33    -9.96     4.09    18.16  \n",
       "2971     0.30   -9.57   -12.04   -12.82     0.41  \n",
       "2972   -58.89  -65.94   -73.44   -63.98   -64.36  \n",
       "2973    15.28  -23.37   -25.55   -29.97   -27.47  \n",
       "2974    85.77   13.50    10.09    18.49    20.94  \n",
       "2975   -82.07  -22.15   -28.22   -74.97   -59.15  \n",
       "2976    28.74    5.11     2.51    -7.15    -3.63  \n",
       "2977    13.97   -9.77     0.32     2.90     5.82  \n",
       "2978     0.63 -170.18   -93.96  -112.74  -100.12  \n",
       "2979   -13.11   -1.72     1.85    -2.09     1.92  \n",
       "2980    33.58  -15.10  -111.61  -147.31  -123.81  \n",
       "2981     2.67  -17.93    -0.94   -16.48    -7.14  \n",
       "2982     1.31   -0.31     1.89    -0.83    -8.11  \n",
       "2983    -2.90  -40.80   -35.80   -31.13   -27.56  \n",
       "2984    11.90 -453.22  -443.06  -414.82  -294.73  \n",
       "2985   -10.60    3.72    -0.62    15.62    -6.60  \n",
       "2986  -184.60 -137.77  -133.70  -192.78  -161.94  \n",
       "2987  -488.62 -944.75  -849.37  -909.75  -904.87  \n",
       "2988    -2.64   -1.07    -6.52    -1.60    -4.24  \n",
       "2989     6.64   -0.38    -6.64    -7.79    -3.01  \n",
       "2990   210.09    3.80    16.33    27.35    21.30  \n",
       "2991     8.75  -10.69    -9.54    -2.48    -8.69  \n",
       "2992   163.02   86.29    13.06   161.22   213.60  \n",
       "2993    28.82  -20.12   -14.41   -43.35   -30.04  \n",
       "2994   -74.95  -46.29    -3.08   -28.43   -48.68  \n",
       "2995   151.75  -24.45   -17.00     3.23    19.28  \n",
       "2996  -136.16   38.03   100.28   -45.64    35.58  \n",
       "2997    -3.47   65.73    88.42    79.07    79.43  \n",
       "2998    -1.50   -4.65   -14.55    -6.41    -2.55  \n",
       "2999   -25.33  -41.31   -16.72   -14.09    27.82  \n",
       "\n",
       "[3000 rows x 3197 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T23:22:05.740042Z",
     "start_time": "2018-02-07T23:22:04.684642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      FLUX.1  FLUX.2  FLUX.3  FLUX.4  FLUX.5  FLUX.6  FLUX.7  FLUX.8  FLUX.9  \\\n",
      "2233  128.17  124.67  113.75  108.95   93.22   74.96   54.90   38.61   26.54   \n",
      "172    23.69   33.61   25.90   17.39    3.60   17.10    5.25   22.64   -4.31   \n",
      "3705    3.93   -3.93   -4.55   -0.81   -4.89   -2.84   -5.27   -0.35   -3.57   \n",
      "1585   30.01   42.47   25.59   27.33   38.41   26.70   24.14   16.66   23.63   \n",
      "4310   26.39   25.00   19.80   20.98   19.89   11.63   15.54   12.78   10.82   \n",
      "\n",
      "      FLUX.10    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
      "2233    19.62    ...          19.19      26.91      18.64      24.87   \n",
      "172      4.40    ...          23.14      14.76      18.82      -2.69   \n",
      "3705    -0.19    ...          -5.93       1.95       1.35      -1.32   \n",
      "1585    21.81    ...          24.51      34.49      24.45      14.93   \n",
      "4310    12.27    ...          -2.84      -2.64       4.37       8.24   \n",
      "\n",
      "      FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
      "2233      30.95      23.43       4.10      -3.78     -11.03     -14.21  \n",
      "172       -4.26      -0.92      14.94      14.51      13.07      27.26  \n",
      "3705      -2.46      -3.50       0.95      -0.30      -1.64       8.62  \n",
      "1585      10.78      25.11       9.15      29.58      27.07      19.05  \n",
      "4310       1.59       7.13      10.94       8.24      10.49      12.49  \n",
      "\n",
      "[5 rows x 3197 columns]\n",
      "      LABEL\n",
      "2233      1\n",
      "172       1\n",
      "3705      1\n",
      "1585      1\n",
      "4310      1\n",
      "      FLUX.1  FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6   FLUX.7   FLUX.8  \\\n",
      "2973   31.47   13.27    19.05    31.56    27.58    39.62    35.38    46.28   \n",
      "2633 -412.43  453.25  1555.91  2402.97  3261.82  4028.29  4861.22  5498.97   \n",
      "398    22.70   30.34    26.82    10.58     4.23    -4.77    -6.71     8.84   \n",
      "481  -268.08 -276.22  -249.69  -252.97  -245.20  -194.97  -189.28  -178.80   \n",
      "3552  -12.86   -9.46   -19.15   -18.75     5.59   -12.34    -9.77   -10.65   \n",
      "\n",
      "       FLUX.9  FLUX.10    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
      "2973    56.82    59.04    ...         -80.93     -87.21     -71.74     -39.94   \n",
      "2633  5985.35  6327.03    ...       15467.79   10965.41    6981.25    3544.69   \n",
      "398      5.44    14.04    ...          67.33      85.22      80.53     119.54   \n",
      "481   -200.39  -172.78    ...        -981.75   -1000.08   -1070.58   -1101.22   \n",
      "3552   -18.46   -10.40    ...          24.37      34.20      23.77      30.22   \n",
      "\n",
      "      FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
      "2973     -47.35     -12.96     -66.24     -75.06     -65.64     -99.16  \n",
      "2633     649.38   -1634.87   -5124.59   -6248.03   -7283.12   -8137.06  \n",
      "398      118.37     133.08      87.32      89.88     116.77      90.83  \n",
      "481    -1125.86   -1133.28   -1132.92   -1174.85   -1220.03   -1263.94  \n",
      "3552      30.90      24.96      11.73      -2.90      -5.98       4.15  \n",
      "\n",
      "[5 rows x 3197 columns]\n",
      "      LABEL\n",
      "2973      1\n",
      "2633      1\n",
      "398       1\n",
      "481       1\n",
      "3552      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# ex_test = pd.read_csv('exoTest.csv')\n",
    "# ex_train = pd.read_csv('exoTrain.csv')\n",
    "label = exo_train[['LABEL']]\n",
    "new_label = exo_train.drop(['LABEL'], axis = 1)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test  = train_test_split(new_label,\n",
    "                                                 label,\n",
    "                                                 test_size=.4)\n",
    "print(x_train[:5])\n",
    "print(y_train[:5])\n",
    "print(x_test[:5])\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T06:20:14.655692Z",
     "start_time": "2018-02-08T06:20:13.709705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MODEL TUNED TO THESE SPECIFIC PARAMETERS AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mae', max_depth=300, max_features=1008,\n",
      "           max_leaf_nodes=300, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=12,\n",
      "           min_samples_split=9, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best'),\n",
      "         learning_rate=0.7, loss='linear', n_estimators=200,\n",
      "         random_state=None)\n",
      "fitting the model\n",
      "model fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -18.31,    4.13,   76.75, ...,   86.07,  171.57,   75.  ],\n",
       "       [ -34.33,  -32.28,  -40.9 , ...,   33.43,   20.08,   52.63],\n",
       "       [  -0.27,   -4.88,   -0.23, ...,   12.61,    7.84,   10.18],\n",
       "       [  -7.81,   -7.97,  -10.1 , ...,   24.25,   21.12,   23.55],\n",
       "       [ 128.71,   82.93,   81.93, ..., -186.62, -154.68, -148.03]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[  119.88,   100.21,    86.46, ...,    35.78,   269.43,    57.72],\n",
       "       [ 5736.59,  5699.98,  5717.16, ..., -2366.19, -2294.86, -2034.72],\n",
       "       [  844.48,   817.49,   770.07, ...,  -162.68,   -36.79,    30.63],\n",
       "       [ -826.  ,  -827.31,  -846.12, ...,  -120.81,  -257.56,  -215.41],\n",
       "       [  -39.57,   -15.88,    -9.16, ...,   -61.98,   -69.34,   -17.84]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Score\n",
      "Score:-> -0.0088 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "\n",
    "regressor = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mae', max_depth=300, max_features=1008,\n",
    "           max_leaf_nodes=300, min_impurity_decrease=0.0,\n",
    "           min_impurity_split=None, min_samples_leaf=12,\n",
    "           min_samples_split=9, min_weight_fraction_leaf=0.0,\n",
    "           presort=False, random_state=None, splitter='best'),\n",
    "         learning_rate=0.7, loss='linear', n_estimators=200,\n",
    "         random_state=None)\n",
    "print(' MODEL TUNED TO THESE SPECIFIC PARAMETERS' , regressor)\n",
    "print('fitting the model')\n",
    "regressor.fit(x_train, y_train)\n",
    "print('model fitted')\n",
    "display(x_train[:5])\n",
    "display(y_train[:5])\n",
    "display(x_test[:5])\n",
    "display(y_test[:5])\n",
    "# TODO: Report the score of the prediction using the testing set\n",
    "print('Generating Score')\n",
    "score = regressor.score(x_test, y_test)\n",
    "print('Score:-> {:.4f} '.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T23:22:42.652419Z",
     "start_time": "2018-02-07T23:22:42.641450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fun with graphs\n"
     ]
    }
   ],
   "source": [
    "print('fun with graphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T23:23:17.516735Z",
     "start_time": "2018-02-07T23:23:17.261239Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "789",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2524\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2525\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2526\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 789",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-408b8fefd008>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m789\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreject_outliers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m789\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreject_outliers_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m789\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2137\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2146\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1842\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3842\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3843\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3844\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2525\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2526\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2527\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 789"
     ]
    }
   ],
   "source": [
    "# outliers = np.abs(x_train- np.mean(x_train)) / np.std(x_train)\n",
    "# display(outliers[60])\n",
    "def reject_outliers(x, m = 2.):\n",
    "    d = np.abs(x_train - np.median(x_train))\n",
    "    mdev = np.median(d)\n",
    "    s = d/mdev if mdev else 0.\n",
    "    return x_train[s<m]\n",
    "\n",
    "def reject_outliers_2(data, m = 2.):\n",
    "    d = np.abs(data - np.median(data))\n",
    "    mdev = np.median(d)\n",
    "    s = d/(mdev if mdev else 1.)\n",
    "    return data[s<m]\n",
    "\n",
    "display(x_train[789])\n",
    "display(reject_outliers(x_train[789]))\n",
    "display(reject_outliers_2(x_train[789]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T23:22:49.190513Z",
     "start_time": "2018-02-07T23:22:45.897Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.title('x,y train(10)') \n",
    "plt.xlabel('x_train')\n",
    "plt.ylabel('y_train')\n",
    "plt.plot(x_train[600]\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T22:53:22.983132Z",
     "start_time": "2018-02-07T22:53:22.947662Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-c6758f1e80d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mICA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T23:04:45.795659Z",
     "start_time": "2018-02-07T23:04:43.428355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      FLUX.1  FLUX.2  FLUX.3  FLUX.4  FLUX.5  FLUX.6  FLUX.7  FLUX.8  FLUX.9  \\\n",
      "4537   10.99    7.28   12.65   13.51   -0.78    6.68   11.52   11.73    7.89   \n",
      "3612   -0.14    0.70   -5.18   -1.60   -2.08    3.06   -3.58    0.31   -5.86   \n",
      "4267  -68.10  -56.34  -49.44   -3.82  -56.86  -28.65   -7.21  -18.67   16.88   \n",
      "4439  -25.69  -47.66  -36.47  -28.12  -42.82  -62.66  -65.80  -67.69  -62.04   \n",
      "83    168.80  174.10  177.41  175.61  146.71  133.01  110.11  108.62   99.65   \n",
      "\n",
      "      FLUX.10    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
      "4537    11.64    ...           3.20       4.86      -0.10       5.31   \n",
      "3612    -3.17    ...           0.10       2.41       3.72       3.39   \n",
      "4267    23.09    ...         -66.03    -101.04    -105.67    -110.29   \n",
      "4439   -74.87    ...         -40.54     -61.30    -101.23     -92.23   \n",
      "83      94.88    ...          21.72       3.76      13.40       4.26   \n",
      "\n",
      "      FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
      "4537       7.83       3.41      13.68      22.10      28.62      25.71  \n",
      "3612       3.62       7.19       3.09       5.59       2.32       7.45  \n",
      "4267    -140.31    -117.31      10.64      39.28      -5.23      -8.33  \n",
      "4439    -106.22     -99.47     -11.67       6.11     -24.62     -16.70  \n",
      "83         1.74      17.03     -21.77       9.29     -16.92     -18.41  \n",
      "\n",
      "[5 rows x 3197 columns]\n",
      "      LABEL\n",
      "4537      1\n",
      "3612      1\n",
      "4267      1\n",
      "4439      1\n",
      "83        1\n",
      "      FLUX.1  FLUX.2  FLUX.3  FLUX.4  FLUX.5  FLUX.6  FLUX.7  FLUX.8  FLUX.9  \\\n",
      "4886  -26.86  -25.21  -20.87  -26.08  -25.63  -20.26  -16.91  -15.19  -18.06   \n",
      "5077  125.57   78.69   98.29   91.16   78.42   45.82   61.69   22.73   39.09   \n",
      "4137    4.07    3.52   -1.01   -0.49    0.65    2.89   -7.78   -3.61   -6.92   \n",
      "1418  -40.90  -87.56 -172.09 -172.03 -182.53 -188.80 -218.08 -278.68 -294.26   \n",
      "4264  405.91  399.73  361.28  345.87  295.94  257.70  245.61  166.09  116.16   \n",
      "\n",
      "      FLUX.10    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
      "4886   -14.79    ...          19.10      19.17      16.39      15.68   \n",
      "5077    10.92    ...          32.35      63.23      57.98      90.43   \n",
      "4137    -1.89    ...          -4.75      -1.59      -3.70      -1.58   \n",
      "1418  -214.87    ...        -122.48     -95.20    -136.79    -178.66   \n",
      "4264   113.70    ...         129.94     114.64     170.30     226.87   \n",
      "\n",
      "      FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
      "4886      13.53      15.39      -2.06       7.39       6.36       7.65  \n",
      "5077     115.12     210.09       3.80      16.33      27.35      21.30  \n",
      "4137      -1.79      -2.74      -3.37       3.66       1.58       4.98  \n",
      "1418    -214.32    -277.12     -23.07     -30.49      -0.87      23.04  \n",
      "4264     273.78     350.06     -46.16     -53.45      38.19      67.78  \n",
      "\n",
      "[5 rows x 3197 columns]\n",
      "      LABEL\n",
      "4886      1\n",
      "5077      1\n",
      "4137      1\n",
      "1418      1\n",
      "4264      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# ex_test = pd.read_csv('exoTest.csv')\n",
    "# ex_train = pd.read_csv('exoTrain.csv')\n",
    "label = exo_train[['LABEL']]\n",
    "new_label = exo_train.drop(['LABEL'], axis = 1)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train,x_test,y_train,y_test  = train_test_split(new_label,\n",
    "                                                 label,\n",
    "                                                 test_size=.4)\n",
    "print(x_train[:5])\n",
    "print(y_train[:5])\n",
    "print(x_test[:5])\n",
    "print(y_test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-02-07T23:05:23.792Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hello\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "regressor = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mae', max_depth=300, max_features=1008,\n",
    "           max_leaf_nodes=300, min_impurity_decrease=0.0,\n",
    "           min_impurity_split=None, min_samples_leaf=12,\n",
    "           min_samples_split=9, min_weight_fraction_leaf=0.0,\n",
    "           presort=False, random_state=None, splitter='best'),\n",
    "         learning_rate=0.7, loss='linear', n_estimators=200,\n",
    "         random_state=None)\n",
    "regressor.fit(x_train, y_train)\n",
    "display(x_train[:5])\n",
    "display(y_train[:5])\n",
    "display(x_test[:5])\n",
    "display(y_test[:5])\n",
    "# TODO: Report the score of the prediction using the testing set\n",
    "score = regressor.score(x_test, y_test)\n",
    "print('Score:-> {:.4f} '.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T22:02:13.886942Z",
     "start_time": "2018-02-07T22:02:11.711919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "params = {'n_estimators': 1200, 'max_depth': 30, 'min_samples_split': 12,\n",
    "          'learning_rate': 0.5, 'loss': 'huber', 'alpha': .4}\n",
    "GBR = GradientBoostingRegressor(**params)\n",
    "\n",
    "GBR.fit(x_train, y_train.ravel())\n",
    "GBR.score(x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T22:13:36.303403Z",
     "start_time": "2018-02-07T22:13:00.929202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7002.363011607264\n",
      "0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans_model = KMeans(n_clusters=3, random_state=1).fit(x_train,y_train)\n",
    "labels = kmeans_model.labels_\n",
    "print(metrics.calinski_harabaz_score(x_train, labels))\n",
    "print('{:.2f}'.format(metrics.silhouette_score(x_train, labels, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T04:58:10.027979Z",
     "start_time": "2018-01-30T04:55:26.894Z"
    }
   },
   "outputs": [],
   "source": [
    "import visuals as vs\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "pca.fit(x_train)\n",
    "pca_samples = pca.transform(x_train[:500])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T22:36:47.804173Z",
     "start_time": "2018-02-07T22:36:33.503876Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f52cd15f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_train, color='darkorange',label='data')\n",
    "plt.plot(y_train, color='cornflowerblue',label='target')\n",
    "# plt.plot(x_train, y_train, color='darkorange', label='data')\n",
    "plt.title('Support Vector Regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
